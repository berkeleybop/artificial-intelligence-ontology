<?xml version="1.0"?>
<rdf:RDF xmlns="http://www.w3.org/2002/07/owl#"
     xml:base="http://www.w3.org/2002/07/owl"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:obo="http://purl.obolibrary.org/obo/"
     xmlns:owl="http://www.w3.org/2002/07/owl#"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:xml="http://www.w3.org/XML/1998/namespace"
     xmlns:xsd="http://www.w3.org/2001/XMLSchema#"
     xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
     xmlns:terms="http://purl.org/dc/terms/"
     xmlns:oboInOwl="http://www.geneontology.org/formats/oboInOwl#">
    <Ontology>
        <dc:description>This ontology models classes and relationships describing deep learning networks, their component layers and activation functions, as well as potential biases.</dc:description>
        <dc:title>Artificial Intelligence Ontology</dc:title>
        <terms:license rdf:resource="http://creativecommons.org/licenses/by/4.0/"/>
    </Ontology>
    


    <!-- 
    ///////////////////////////////////////////////////////////////////////////////////////
    //
    // Annotation properties
    //
    ///////////////////////////////////////////////////////////////////////////////////////
     -->

    


    <!-- http://purl.obolibrary.org/obo/IAO_0000115 -->

    <AnnotationProperty rdf:about="http://purl.obolibrary.org/obo/IAO_0000115"/>
    


    <!-- http://purl.org/dc/elements/1.1/description -->

    <AnnotationProperty rdf:about="http://purl.org/dc/elements/1.1/description"/>
    


    <!-- http://purl.org/dc/elements/1.1/title -->

    <AnnotationProperty rdf:about="http://purl.org/dc/elements/1.1/title"/>
    


    <!-- http://purl.org/dc/terms/license -->

    <AnnotationProperty rdf:about="http://purl.org/dc/terms/license"/>
    


    <!-- http://www.geneontology.org/formats/oboInOwl#hasDbXref -->

    <AnnotationProperty rdf:about="http://www.geneontology.org/formats/oboInOwl#hasDbXref"/>
    


    <!-- http://www.geneontology.org/formats/oboInOwl#hasExactSynonym -->

    <AnnotationProperty rdf:about="http://www.geneontology.org/formats/oboInOwl#hasExactSynonym"/>
    


    <!-- http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym -->

    <AnnotationProperty rdf:about="http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym"/>
    


    <!-- http://www.geneontology.org/formats/oboInOwl#inSubset -->

    <AnnotationProperty rdf:about="http://www.geneontology.org/formats/oboInOwl#inSubset"/>
    


    <!-- 
    ///////////////////////////////////////////////////////////////////////////////////////
    //
    // Classes
    //
    ///////////////////////////////////////////////////////////////////////////////////////
     -->

    


    <!-- https://w3id.org/aio/AbstractRNNCell -->

    <Class rdf:about="https://w3id.org/aio/AbstractRNNCell">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Abstract object representing an RNN cell. This is the base class for implementing RNN cells with custom behavior.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AbstractRNNCell</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AbstractRNNCell"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Abstract object representing an RNN cell. This is the base class for implementing RNN cells with custom behavior.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/AbstractRNNCell</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ActivationLayer -->

    <Class rdf:about="https://w3id.org/aio/ActivationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Applies an activation function to an output.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Activation Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies an activation function to an output.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ActiveLearning -->

    <Class rdf:about="https://w3id.org/aio/ActiveLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that interactively query a user or another information source to label new data points with the desired outputs.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Query Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Active Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ActiveLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that interactively query a user or another information source to label new data points with the desired outputs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Active_learning_(machine_learning)|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ActivityBias -->

    <Class rdf:about="https://w3id.org/aio/ActivityBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Selection bias occurring when systems/platforms get training data from their most active users, rather than less active or inactive users.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Activity Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ActivityBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Selection bias occurring when systems/platforms get training data from their most active users, rather than less active or inactive users.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Interpretive_bias|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ActivityRegularizationLayer -->

    <Class rdf:about="https://w3id.org/aio/ActivityRegularizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Layer that applies an update to the cost function based input activity.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ActivityRegularization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ActivityRegularizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that applies an update to the cost function based input activity.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ActivityRegularization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdaptiveAvgPool1DLayer -->

    <Class rdf:about="https://w3id.org/aio/AdaptiveAvgPool1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 1D adaptive average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AdaptiveAvgPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AdaptiveAvgPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdaptiveAvgPool1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdaptiveAvgPool1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 1D adaptive average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdaptiveAvgPool2DLayer -->

    <Class rdf:about="https://w3id.org/aio/AdaptiveAvgPool2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 2D adaptive average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AdaptiveAvgPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AdaptiveAvgPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdaptiveAvgPool2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdaptiveAvgPool2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 2D adaptive average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdaptiveAvgPool3DLayer -->

    <Class rdf:about="https://w3id.org/aio/AdaptiveAvgPool3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 3D adaptive average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AdaptiveAvgPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AdaptiveAvgPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdaptiveAvgPool3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdaptiveAvgPool3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 3D adaptive average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdaptiveMaxPool1DLayer -->

    <Class rdf:about="https://w3id.org/aio/AdaptiveMaxPool1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 1D adaptive max pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AdaptiveMaxPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AdaptiveMaxPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdaptiveMaxPool1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdaptiveMaxPool1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 1D adaptive max pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdaptiveMaxPool2DLayer -->

    <Class rdf:about="https://w3id.org/aio/AdaptiveMaxPool2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 2D adaptive max pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AdaptiveMaxPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AdaptiveMaxPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdaptiveMaxPool2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdaptiveMaxPool2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 2D adaptive max pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdaptiveMaxPool3DLayer -->

    <Class rdf:about="https://w3id.org/aio/AdaptiveMaxPool3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 3D adaptive max pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AdaptiveMaxPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AdaptiveMaxPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdaptiveMaxPool3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdaptiveMaxPool3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 3D adaptive max pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AddLayer -->

    <Class rdf:about="https://w3id.org/aio/AddLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that adds a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Add Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AddLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that adds a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AdditiveAttentionLayer -->

    <Class rdf:about="https://w3id.org/aio/AdditiveAttentionLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AttentionLayer"/>
        <obo:IAO_0000115>Additive attention layer, a.k.a. Bahdanau-style attention.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AdditiveAttention Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AdditiveAttentionLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Additive attention layer, a.k.a. Bahdanau-style attention.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AlphaDropoutLayer -->

    <Class rdf:about="https://w3id.org/aio/AlphaDropoutLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Applies Alpha Dropout to the input. Alpha Dropout is a Dropout that keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout. Alpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AlphaDropout Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AlphaDropoutLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Alpha Dropout to the input. Alpha Dropout is a Dropout that keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout. Alpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AmplificationBias -->

    <Class rdf:about="https://w3id.org/aio/AmplificationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProcessingBias"/>
        <obo:IAO_0000115>Bias arising when the distribution over prediction outputs is skewed compared to the prior distribution of the prediction target.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Amplification Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AmplificationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when the distribution over prediction outputs is skewed compared to the prior distribution of the prediction target.</annotatedTarget>
        <oboInOwl:hasDbXref>https://royalsocietypublishing.org/doi/10.1098/rspb.2019.0165#d1e5237|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AnchoringBias -->

    <Class rdf:about="https://w3id.org/aio/AnchoringBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>The influence of a reference point or anchor on decisions, leading to insufficient adjustment from that anchor point.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Anchoring Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AnchoringBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The influence of a reference point or anchor on decisions, leading to insufficient adjustment from that anchor point.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AnnotatorReportingBias -->

    <Class rdf:about="https://w3id.org/aio/AnnotatorReportingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>When users rely on automation as a heuristic replacement for their own information seeking and processing.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Annotator Reporting Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AnnotatorReportingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>When users rely on automation as a heuristic replacement for their own information seeking and processing.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ArtificialNeuralNetwork -->

    <Class rdf:about="https://w3id.org/aio/ArtificialNeuralNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>An artificial neural network (ANN) is based on a collection of connected units or nodes called artificial neurons, modeled after biological neurons, with connections transmitting signals processed by non-linear functions.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ANN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>NN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Artificial Neural Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ArtificialNeuralNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An artificial neural network (ANN) is based on a collection of connected units or nodes called artificial neurons, modeled after biological neurons, with connections transmitting signals processed by non-linear functions.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Artificial_neural_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AssociationRuleLearning -->

    <Class rdf:about="https://w3id.org/aio/AssociationRuleLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SupervisedLearning"/>
        <obo:IAO_0000115>A rule-based machine learning method for discovering interesting relations between variables in large databases.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Association Rule Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AssociationRuleLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A rule-based machine learning method for discovering interesting relations between variables in large databases.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Association_rule_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AttentionLayer -->

    <Class rdf:about="https://w3id.org/aio/AttentionLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Dot-product attention layer, a.k.a. Luong-style attention.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Attention Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AttentionLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Dot-product attention layer, a.k.a. Luong-style attention.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutoEncoderNetwork -->

    <Class rdf:about="https://w3id.org/aio/AutoEncoderNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UnsupervisedPretrainedNetwork"/>
        <obo:IAO_0000115>An autoencoder is an artificial neural network used for learning efficient codings of unlabeled data, training the network to ignore insignificant data and regenerate input from encoding.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AE</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Matched Output-Input</rdfs:comment>
        <rdfs:label>Auto Encoder Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutoEncoderNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An autoencoder is an artificial neural network used for learning efficient codings of unlabeled data, training the network to ignore insignificant data and regenerate input from encoding.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Autoencoder|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutomationComplacencyBias -->

    <Class rdf:about="https://w3id.org/aio/AutomationComplacencyBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Over-reliance on automated systems, leading to attenuated human skills, such as with spelling and autocorrect.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Automation Complaceny</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Automation Complacency Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutomationComplacencyBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Over-reliance on automated systems, leading to attenuated human skills, such as with spelling and autocorrect.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutoregressiveLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/AutoregressiveLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>An autoregressive language model generates text sequentially, predicting one token at a time based on the previously generated tokens. It excels at natural language generation tasks by modeling the probability distribution over sequences of tokens.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Autoregressive Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>generative language model</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>sequence-to-sequence model</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Autoregressive Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutoregressiveLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An autoregressive language model generates text sequentially, predicting one token at a time based on the previously generated tokens. It excels at natural language generation tasks by modeling the probability distribution over sequences of tokens.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AvailabilityHeuristicBias -->

    <Class rdf:about="https://w3id.org/aio/AvailabilityHeuristicBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>A mental shortcut where easily recalled information is overweighted in judgment and decision-making.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Availability Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Availability Heuristic</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Availability Heuristic Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AvailabilityHeuristicBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A mental shortcut where easily recalled information is overweighted in judgment and decision-making.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AverageLayer -->

    <Class rdf:about="https://w3id.org/aio/AverageLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that averages a list of inputs element-wise. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Average Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AverageLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that averages a list of inputs element-wise. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Average</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AveragePooling1DLayer -->

    <Class rdf:about="https://w3id.org/aio/AveragePooling1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Average pooling for temporal data. Downsamples the input representation by taking the average value over the window defined by pool_size. The window is shifted by strides. The resulting output when using &quot;valid&quot; padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides). The resulting output shape when using the &quot;same&quot; padding option is: output_shape = input_shape / strides.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AvgPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AvgPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AveragePooling1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AveragePooling1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Average pooling for temporal data. Downsamples the input representation by taking the average value over the window defined by pool_size. The window is shifted by strides. The resulting output when using &quot;valid&quot; padding option has a shape of: output_shape = (input_shape - pool_size + 1) / strides). The resulting output shape when using the &quot;same&quot; padding option is: output_shape = input_shape / strides.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AveragePooling2DLayer -->

    <Class rdf:about="https://w3id.org/aio/AveragePooling2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Average pooling operation for spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension. The resulting output when using &quot;valid&quot; padding option has a shape (number of rows or columns) of: output_shape = math.floor((input_shape - pool_size) / strides) + 1 (when input_shape &gt;= pool_size). The resulting output shape when using the &quot;same&quot; padding option is: output_shape = math.floor((input_shape - 1) / strides) + 1.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AvgPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AvgPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AveragePooling2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AveragePooling2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Average pooling operation for spatial data. Downsamples the input along its spatial dimensions (height and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension. The resulting output when using &quot;valid&quot; padding option has a shape (number of rows or columns) of: output_shape = math.floor((input_shape - pool_size) / strides) + 1 (when input_shape &gt;= pool_size). The resulting output shape when using the &quot;same&quot; padding option is: output_shape = math.floor((input_shape - 1) / strides) + 1.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AveragePooling3DLayer -->

    <Class rdf:about="https://w3id.org/aio/AveragePooling3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Average pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AvgPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AvgPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AveragePooling3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AveragePooling3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Average pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the average value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AvgPool1DLayer -->

    <Class rdf:about="https://w3id.org/aio/AvgPool1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 1D average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AvgPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AvgPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AvgPool1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AvgPool1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 1D average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AvgPool2DLayer -->

    <Class rdf:about="https://w3id.org/aio/AvgPool2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 2D average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AvgPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AvgPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AvgPool2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AvgPool2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 2D average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AvgPool3DLayer -->

    <Class rdf:about="https://w3id.org/aio/AvgPool3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 3D average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>AvgPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>AvgPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>AvgPool3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AvgPool3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 3D average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BatchNorm1DLayer -->

    <Class rdf:about="https://w3id.org/aio/BatchNorm1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>Applies Batch Normalization over a 2D or 3D input as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>BatchNorm1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>BatchNorm1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>BatchNorm1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BatchNorm1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Batch Normalization over a 2D or 3D input as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BatchNorm2DLayer -->

    <Class rdf:about="https://w3id.org/aio/BatchNorm2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>BatchNorm2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>BatchNorm2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>BatchNorm2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BatchNorm2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BatchNorm3DLayer -->

    <Class rdf:about="https://w3id.org/aio/BatchNorm3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>BatchNorm3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>BatchNorm3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>BatchNorm3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BatchNorm3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BatchNormalizationLayer -->

    <Class rdf:about="https://w3id.org/aio/BatchNormalizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Layer that normalizes its inputs. Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1. Importantly, batch normalization works differently during training and during inference. During training (i.e. when using fit() or when calling the layer/model with the argument training=True), the layer normalizes its output using the mean and standard deviation of the current batch of inputs. That is to say, for each channel being normalized, the layer returns gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta, where: epsilon is small constant (configurable as part of the constructor arguments), gamma is a learned scaling factor (initialized as 1), which can be disabled by passing scale=False to the constructor. beta is a learned offset factor (initialized as 0), which can be disabled by passing center=False to the constructor. During inference (i.e. when using evaluate() or predict() or when calling the layer/model with the argument training=False (which is the default), the layer normalizes its output using a moving average of the mean and standard deviation of the batches it has seen during training. That is to say, it returns gamma * (batch - self.moving_mean) / sqrt(self.moving_var + epsilon) + beta. self.moving_mean and self.moving_var are non-trainable variables that are updated each time the layer in called in training mode, as such: moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum) moving_var = moving_var * momentum + var(batch) * (1 - momentum).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>BatchNormalization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that normalizes its inputs. Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1. Importantly, batch normalization works differently during training and during inference. During training (i.e. when using fit() or when calling the layer/model with the argument training=True), the layer normalizes its output using the mean and standard deviation of the current batch of inputs. That is to say, for each channel being normalized, the layer returns gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta, where: epsilon is small constant (configurable as part of the constructor arguments), gamma is a learned scaling factor (initialized as 1), which can be disabled by passing scale=False to the constructor. beta is a learned offset factor (initialized as 0), which can be disabled by passing center=False to the constructor. During inference (i.e. when using evaluate() or predict() or when calling the layer/model with the argument training=False (which is the default), the layer normalizes its output using a moving average of the mean and standard deviation of the batches it has seen during training. That is to say, it returns gamma * (batch - self.moving_mean) / sqrt(self.moving_var + epsilon) + beta. self.moving_mean and self.moving_var are non-trainable variables that are updated each time the layer in called in training mode, as such: moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum) moving_var = moving_var * momentum + var(batch) * (1 - momentum).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BayesianNetwork -->

    <Class rdf:about="https://w3id.org/aio/BayesianNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>A probabilistic graphical model representing variables and their conditional dependencies via a directed acyclic graph (DAG).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Bayesian Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BayesianNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A probabilistic graphical model representing variables and their conditional dependencies via a directed acyclic graph (DAG).</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Bayesian_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BehavioralBias -->

    <Class rdf:about="https://w3id.org/aio/BehavioralBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Systematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Behavioral Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BehavioralBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Bias -->

    <Class rdf:about="https://w3id.org/aio/Bias">
        <obo:IAO_0000115>Systematic error introduced into sampling or testing by selecting or encouraging one outcome or answer over others.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Bias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic error introduced into sampling or testing by selecting or encouraging one outcome or answer over others.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.merriam-webster.com/dictionary/bias|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Biclustering -->

    <Class rdf:about="https://w3id.org/aio/Biclustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that simultaneously cluster the rows and columns of a matrix to identify submatrices with coherent patterns.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Block Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Co-clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Joint Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Two-mode Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Two-way Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Biclustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Biclustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that simultaneously cluster the rows and columns of a matrix to identify submatrices with coherent patterns.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Biclustering|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BidirectionalLayer -->

    <Class rdf:about="https://w3id.org/aio/BidirectionalLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>Bidirectional wrapper for RNNs.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Bidirectional Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BidirectionalLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bidirectional wrapper for RNNs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BidirectionalTransformerLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/BidirectionalTransformerLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/TransformerLanguageModel"/>
        <obo:IAO_0000115>A bidirectional transformer language model, such as BERT, uses the transformer architecture to build deep bidirectional representations by predicting masked tokens based on their context.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>BERT</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Bidirectional Transformer LM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Bidirectional Transformer Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BidirectionalTransformerLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A bidirectional transformer language model, such as BERT, uses the transformer architecture to build deep bidirectional representations by predicting masked tokens based on their context.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/1810.04805|https://en.wikipedia.org/wiki/BERT_(language_model)|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BinaryClassification -->

    <Class rdf:about="https://w3id.org/aio/BinaryClassification">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Classification"/>
        <obo:IAO_0000115>Methods that classify elements into two groups based on a classification rule.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Binary Classification</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BinaryClassification"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that classify elements into two groups based on a classification rule.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Binary_classification|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/BoltzmannMachineNetwork -->

    <Class rdf:about="https://w3id.org/aio/BoltzmannMachineNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SymmetricallyConnectedNetwork"/>
        <obo:IAO_0000115>A Boltzmann machine is a type of stochastic recurrent neural network and Markov random field, translated from statistical physics for use in cognitive science.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>BM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Sherrington–Kirkpatrick model with external field</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>stochastic Hopfield network with hidden units</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>stochastic Ising-Lenz-Little model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Backfed Input, Probabilistic Hidden</rdfs:comment>
        <rdfs:label>Boltzmann Machine Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/BoltzmannMachineNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A Boltzmann machine is a type of stochastic recurrent neural network and Markov random field, translated from statistical physics for use in cognitive science.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Boltzmann_machine|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer -->

    <Class rdf:about="https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that performs categorical data preprocessing operations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Categorical Features Preprocessing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that performs categorical data preprocessing operations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/guides/preprocessing_layers/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CategoryEncodingLayer -->

    <Class rdf:about="https://w3id.org/aio/CategoryEncodingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which encodes integer features. This layer provides options for condensing data into a categorical encoding when the total number of tokens are known in advance. It accepts integer values as inputs, and it outputs a dense or sparse representation of those inputs. For integer inputs where the total number of tokens is not known, use tf.keras.layers.IntegerLookup instead.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>CategoryEncoding Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CategoryEncodingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which encodes integer features. This layer provides options for condensing data into a categorical encoding when the total number of tokens are known in advance. It accepts integer values as inputs, and it outputs a dense or sparse representation of those inputs. For integer inputs where the total number of tokens is not known, use tf.keras.layers.IntegerLookup instead.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CausalGraphicalModel -->

    <Class rdf:about="https://w3id.org/aio/CausalGraphicalModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProbabilisticGraphicalModel"/>
        <obo:IAO_0000115>Probabilistic graphical models used to encode assumptions about the data-generating process.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Casaul Bayesian Network</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Casaul Graph</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>DAG</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Directed Acyclic Graph</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Path Diagram</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Causal Graphical Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CausalGraphicalModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Probabilistic graphical models used to encode assumptions about the data-generating process.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Causal_graph|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CausalLLM -->

    <Class rdf:about="https://w3id.org/aio/CausalLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A causal LLM only attends to previous tokens in the sequence when generating text, modeling the probability distribution autoregressively from left-to-right or causally.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Causal Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>autoregressive</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>unidirectional</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Causal LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CausalLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A causal LLM only attends to previous tokens in the sequence when generating text, modeling the probability distribution autoregressively from left-to-right or causally.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CenterCropLayer -->

    <Class rdf:about="https://w3id.org/aio/CenterCropLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ImagePreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which crops images. This layers crops the central portion of the images to a target size. If an image is smaller than the target size, it will be resized and cropped so as to return the largest possible window in the image that matches the target aspect ratio. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>CenterCrop Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CenterCropLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which crops images. This layers crops the central portion of the images to a target size. If an image is smaller than the target size, it will be resized and cropped so as to return the largest possible window in the image that matches the target aspect ratio. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Classification -->

    <Class rdf:about="https://w3id.org/aio/Classification">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SupervisedLearning"/>
        <obo:IAO_0000115>Methods that distinguish and distribute kinds of &quot;things&quot; into different groups.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Classification</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Classification"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that distinguish and distribute kinds of &quot;things&quot; into different groups.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Classification_(general_theory)|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Cleaning -->

    <Class rdf:about="https://w3id.org/aio/Cleaning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DataPreparation"/>
        <obo:IAO_0000115>The process of removing noise, inconsistencies, and irrelevant information from data to enhance its quality and prepare it for analysis or further processing.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Data Cleansing</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Standardization</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Data cleaning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Text normalization</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Cleaning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Cleaning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of removing noise, inconsistencies, and irrelevant information from data to enhance its quality and prepare it for analysis or further processing.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Clustering -->

    <Class rdf:about="https://w3id.org/aio/Clustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that group a set of objects such that objects in the same group are more similar to each other than to those in other groups.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Cluster analysis</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Clustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Clustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that group a set of objects such that objects in the same group are more similar to each other than to those in other groups.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Cluster_analysis|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CognitiveBias -->

    <Class rdf:about="https://w3id.org/aio/CognitiveBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Systematic deviation from rational judgment and decision-making, including adaptive mental shortcuts known as heuristics.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Cognitive Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CognitiveBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic deviation from rational judgment and decision-making, including adaptive mental shortcuts known as heuristics.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CompositionalGeneralizationLLM -->

    <Class rdf:about="https://w3id.org/aio/CompositionalGeneralizationLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A compositional generalization LLM is trained to understand and recombine the underlying compositional structures in language, enabling better generalization to novel combinations and out-of-distribution examples.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Compositional Generalization Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>out-of-distribution generalization</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>systematic generalization</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Compositional Generalization LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CompositionalGeneralizationLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A compositional generalization LLM is trained to understand and recombine the underlying compositional structures in language, enabling better generalization to novel combinations and out-of-distribution examples.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ComputationalBias -->

    <Class rdf:about="https://w3id.org/aio/ComputationalBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>Systematic tendency causing differences between results and facts in the process of data analysis, including the source of data, the estimator chosen, and analysis methods.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Statistical Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Computational Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ComputationalBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic tendency causing differences between results and facts in the process of data analysis, including the source of data, the estimator chosen, and analysis methods.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConcatenateLayer -->

    <Class rdf:about="https://w3id.org/aio/ConcatenateLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that concatenates a list of inputs. It takes as input a list of tensors, all of the same shape except for the concatenation axis, and returns a single tensor that is the concatenation of all inputs.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Concatenate Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConcatenateLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that concatenates a list of inputs. It takes as input a list of tensors, all of the same shape except for the concatenation axis, and returns a single tensor that is the concatenation of all inputs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConceptDriftBias -->

    <Class rdf:about="https://w3id.org/aio/ConceptDriftBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Bias due to the use of a system outside its planned domain of application, causing performance gaps between laboratory settings and the real world.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Concept Drift</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Concept Drift Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConceptDriftBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias due to the use of a system outside its planned domain of application, causing performance gaps between laboratory settings and the real world.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConfirmationBias -->

    <Class rdf:about="https://w3id.org/aio/ConfirmationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>The tendency to prefer information that confirms existing beliefs, influencing the search for, interpretation of, and recall of information.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Confirmation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConfirmationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The tendency to prefer information that confirms existing beliefs, influencing the search for, interpretation of, and recall of information.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConsumerBias -->

    <Class rdf:about="https://w3id.org/aio/ConsumerBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Bias arising when an algorithm or platform provides users a venue to express their biases, occurring from either side in a digital interaction.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Consumer Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConsumerBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when an algorithm or platform provides users a venue to express their biases, occurring from either side in a digital interaction.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ContentProductionBias -->

    <Class rdf:about="https://w3id.org/aio/ContentProductionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Bias from structural, lexical, semantic, and syntactic differences in user-generated content.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Content Production Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ContentProductionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias from structural, lexical, semantic, and syntactic differences in user-generated content.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ContinualLearning -->

    <Class rdf:about="https://w3id.org/aio/ContinualLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Learning a model for sequential tasks without forgetting knowledge from preceding tasks, with no access to old task data during new task training.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Incremental Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Life-Long Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Continual Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ContinualLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Learning a model for sequential tasks without forgetting knowledge from preceding tasks, with no access to old task data during new task training.</annotatedTarget>
        <oboInOwl:hasDbXref>https://paperswithcode.com/task/continual-learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ContinualLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/ContinualLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A continual learning LLM continually acquires new knowledge and skills over time without forgetting previously learned information. This allows the model to adapt and expand its capabilities as new data becomes available.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>CL-Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Continual Learning Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>catastrophic forgetting</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>lifelong learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Continual Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ContinualLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A continual learning LLM continually acquires new knowledge and skills over time without forgetting previously learned information. This allows the model to adapt and expand its capabilities as new data becomes available.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ContrastiveLearning -->

    <Class rdf:about="https://w3id.org/aio/ContrastiveLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Contrastive learning is a self-supervised learning approach in which the model learns to distinguish between similar and dissimilar pairs of data samples. By maximizing the similarity between positive pairs (similar samples) and minimizing the similarity between negative pairs (dissimilar samples), the model learns to capture meaningful representations of the data. This method is particularly effective for representation learning and is widely used in tasks such as image classification, clustering, and retrieval. Contrastive learning techniques often employ loss functions such as the contrastive loss or the triplet loss to achieve these objectives.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Contrastive Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ContrastiveLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Contrastive learning is a self-supervised learning approach in which the model learns to distinguish between similar and dissimilar pairs of data samples. By maximizing the similarity between positive pairs (similar samples) and minimizing the similarity between negative pairs (dissimilar samples), the model learns to capture meaningful representations of the data. This method is particularly effective for representation learning and is widely used in tasks such as image classification, clustering, and retrieval. Contrastive learning techniques often employ loss functions such as the contrastive loss or the triplet loss to achieve these objectives.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2202.14037|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ContrastiveLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/ContrastiveLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A contrastive learning LLM is trained to pull semantically similar samples closer together and push dissimilar samples apart in the representation space, learning high-quality features useful for downstream tasks.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Contrastive Learning LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Representation learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Contrastive Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ContrastiveLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A contrastive learning LLM is trained to pull semantically similar samples closer together and push dissimilar samples apart in the representation space, learning high-quality features useful for downstream tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ControllableLLM -->

    <Class rdf:about="https://w3id.org/aio/ControllableLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A controllable LLM allows for explicit control over certain attributes of the generated text, such as style, tone, topic, or other desired characteristics, through conditioning or specialized training objectives.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Controllable Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>conditional generation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>guided generation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Controllable LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ControllableLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A controllable LLM allows for explicit control over certain attributes of the generated text, such as style, tone, topic, or other desired characteristics, through conditioning or specialized training objectives.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConvLSTM1DLayer -->

    <Class rdf:about="https://w3id.org/aio/ConvLSTM1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>1D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ConvLSTM1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConvLSTM1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>1D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConvLSTM2DLayer -->

    <Class rdf:about="https://w3id.org/aio/ConvLSTM2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>2D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ConvLSTM2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConvLSTM2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>2D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConvLSTM3DLayer -->

    <Class rdf:about="https://w3id.org/aio/ConvLSTM3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>3D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ConvLSTM3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConvLSTM3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>3D Convolutional LSTM. Similar to an LSTM layer, but the input transformations and recurrent transformations are both convolutional.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Convolution1DLayer -->

    <Class rdf:about="https://w3id.org/aio/Convolution1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>1D convolution layer (e.g. temporal convolution).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Conv1D Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Conv1d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution1d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>nn.Conv1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolution1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Convolution1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>1D convolution layer (e.g. temporal convolution).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Convolution1DTransposeLayer -->

    <Class rdf:about="https://w3id.org/aio/Convolution1DTransposeLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 3) for data with 128 time steps and 3 channels.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Conv1DTranspose Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>ConvTranspose1d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution1DTranspose</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution1dTranspose</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>nn.ConvTranspose1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolution1DTranspose Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Convolution1DTransposeLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 3) for data with 128 time steps and 3 channels.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1DTranspose</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Convolution2DLayer -->

    <Class rdf:about="https://w3id.org/aio/Convolution2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=&quot;channels_last&quot;. You can use None when a dimension has variable size.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Conv2D Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Conv2d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution2d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>nn.Conv2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolution2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Convolution2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=&quot;channels_last&quot;. You can use None when a dimension has variable size.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Convolution2DTransposeLayer -->

    <Class rdf:about="https://w3id.org/aio/Convolution2DTransposeLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Transposed convolution layer (sometimes called Deconvolution).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Conv2DTranspose Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>ConvTranspose2d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution2DTranspose</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution2dTranspose</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>nn.ConvTranspose2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolution2DTranspose Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Convolution2DTransposeLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Transposed convolution layer (sometimes called Deconvolution).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Convolution3DLayer -->

    <Class rdf:about="https://w3id.org/aio/Convolution3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>3D convolution layer (e.g. spatial convolution over volumes). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 128, 1) for 128x128x128 volumes with a single channel, in data_format=&quot;channels_last&quot;.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Conv3D Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Conv3d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution3d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>nn.Conv3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolution3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Convolution3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>3D convolution layer (e.g. spatial convolution over volumes). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 128, 1) for 128x128x128 volumes with a single channel, in data_format=&quot;channels_last&quot;.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Convolution3DTransposeLayer -->

    <Class rdf:about="https://w3id.org/aio/Convolution3DTransposeLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 128, 3) for a 128x128x128 volume with 3 channels if data_format=&quot;channels_last&quot;.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Conv3DTranspose Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>ConvTranspose3d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution3DTranspose</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolution3dTranspose</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>nn.ConvTranspose3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolution3DTranspose Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Convolution3DTransposeLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Transposed convolution layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers or None, does not include the sample axis), e.g. input_shape=(128, 128, 128, 3) for a 128x128x128 volume with 3 channels if data_format=&quot;channels_last&quot;.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3DTranspose</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ConvolutionalLayer -->

    <Class rdf:about="https://w3id.org/aio/ConvolutionalLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A convolutional layer is the main building block of a CNN. It contains a set of filters (or kernels), parameters of which are to be learned throughout the training. The size of the filters is usually smaller than the actual image. Each filter convolves with the image and creates an activation map.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Convolutional Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A convolutional layer is the main building block of a CNN. It contains a set of filters (or kernels), parameters of which are to be learned throughout the training. The size of the filters is usually smaller than the actual image. Each filter convolves with the image and creates an activation map.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.sciencedirect.com/topics/engineering/convolutional-layer#:~:text=A%20convolutional%20layer%20is%20the,and%20creates%20an%20activation%20map.</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Cropping1DLayer -->

    <Class rdf:about="https://w3id.org/aio/Cropping1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Cropping layer for 1D input (e.g. temporal sequence). It crops along the time dimension (axis 1).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Cropping1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Cropping1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Cropping layer for 1D input (e.g. temporal sequence). It crops along the time dimension (axis 1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Cropping1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Cropping2DLayer -->

    <Class rdf:about="https://w3id.org/aio/Cropping2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Cropping layer for 2D input (e.g. picture). It crops along spatial dimensions, i.e. height and width.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Cropping2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Cropping2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Cropping layer for 2D input (e.g. picture). It crops along spatial dimensions, i.e. height and width.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Cropping2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Cropping3DLayer -->

    <Class rdf:about="https://w3id.org/aio/Cropping3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Cropping3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Cropping3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Cropping3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Cross-DomainLLM -->

    <Class rdf:about="https://w3id.org/aio/Cross-DomainLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A cross-domain LLM performs well across a wide range of domains without significant loss in performance, facilitated by advanced domain adaptation techniques.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Domain-General LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>cross-domain transfer</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>domain adaptation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Cross-Domain LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Cross-DomainLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A cross-domain LLM performs well across a wide range of domains without significant loss in performance, facilitated by advanced domain adaptation techniques.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CurriculumLearning -->

    <Class rdf:about="https://w3id.org/aio/CurriculumLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/TrainingStrategies"/>
        <obo:IAO_0000115>A training strategy in machine learning where models are trained on data in a meaningful order, starting with simpler examples and gradually increasing the complexity, to improve learning efficiency and model performance.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Sequential Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Structured Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Complexity grading</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Sequential learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Curriculum Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CurriculumLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A training strategy in machine learning where models are trained on data in a meaningful order, starting with simpler examples and gradually increasing the complexity, to improve learning efficiency and model performance.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/CurriculumLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/CurriculumLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A curriculum learning LLM is trained by presenting learning examples in a meaningful order from simple to complex, mimicking the learning trajectory followed by humans.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Curriculum Learning LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Learning progression</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Curriculum Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/CurriculumLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A curriculum learning LLM is trained by presenting learning examples in a meaningful order from simple to complex, mimicking the learning trajectory followed by humans.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Data-to-TextLLM -->

    <Class rdf:about="https://w3id.org/aio/Data-to-TextLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A data-to-text LLM generates natural language descriptions from structured data sources like tables, graphs, and knowledge bases, requiring grounding in meaning representations.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Data-to-Text LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Meaning representation</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Data-to-Text LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Data-to-TextLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A data-to-text LLM generates natural language descriptions from structured data sources like tables, graphs, and knowledge bases, requiring grounding in meaning representations.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DataAugmentation -->

    <Class rdf:about="https://w3id.org/aio/DataAugmentation">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DataEnhancement"/>
        <obo:IAO_0000115>A technique used to increase the diversity and quantity of training data by applying various transformations such as rotation, scaling, flipping, and cropping to existing data samples, enhancing the robustness and performance of machine learning models.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Data Enrichment</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Data Expansion</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Paraphrasing</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Synonym replacement</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Data Augmentation</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DataAugmentation"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A technique used to increase the diversity and quantity of training data by applying various transformations such as rotation, scaling, flipping, and cropping to existing data samples, enhancing the robustness and performance of machine learning models.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DataDredgingBias -->

    <Class rdf:about="https://w3id.org/aio/DataDredgingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Statistical bias where testing many hypotheses in a dataset may yield apparent statistical significance even when results are nonsignificant.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Data Dredging</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Data Dredging Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DataDredgingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Statistical bias where testing many hypotheses in a dataset may yield apparent statistical significance even when results are nonsignificant.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DataEnhancement -->

    <Class rdf:about="https://w3id.org/aio/DataEnhancement">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Preprocessing"/>
        <obo:IAO_0000115>Techniques used to improve the quality, diversity, and volume of data available for training machine learning models, such as data augmentation, synthesis, and enrichment, to enhance model robustness and accuracy.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>DataEnhancement</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DataEnhancement"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Techniques used to improve the quality, diversity, and volume of data available for training machine learning models, such as data augmentation, synthesis, and enrichment, to enhance model robustness and accuracy.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DataGenerationBias -->

    <Class rdf:about="https://w3id.org/aio/DataGenerationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias from adding synthetic or redundant data samples to a dataset.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Data Generation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DataGenerationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias from adding synthetic or redundant data samples to a dataset.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Selection_bias|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DataImputation -->

    <Class rdf:about="https://w3id.org/aio/DataImputation">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that replace missing data with substituted values.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Data Imputation</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DataImputation"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that replace missing data with substituted values.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Imputation_(statistics)|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DataPreparation -->

    <Class rdf:about="https://w3id.org/aio/DataPreparation">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Preprocessing"/>
        <obo:IAO_0000115>The process of cleaning, transforming, and organizing raw data into a suitable format for analysis and modeling, ensuring the quality and relevance of the data for machine learning tasks.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Data Assembly</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Data Curation</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Data Processing</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Data Preparation</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DataPreparation"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of cleaning, transforming, and organizing raw data into a suitable format for analysis and modeling, ensuring the quality and relevance of the data for machine learning tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DecisionTree -->

    <Class rdf:about="https://w3id.org/aio/DecisionTree">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Classification"/>
        <obo:IAO_0000115>A decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utilities.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Decision Tree</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DecisionTree"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utilities.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Decision_tree|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DecoderLLM -->

    <Class rdf:about="https://w3id.org/aio/DecoderLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A decoder-only architecture consisting of only a decoder, trained to predict the next token in a sequence given the previous tokens. Unlike the encoder-decoder architecture, it does not have an explicit encoder and encodes information implicitly in the hidden state of the decoder, updated at each step of the generation process.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Decoder LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DecoderLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A decoder-only architecture consisting of only a decoder, trained to predict the next token in a sequence given the previous tokens. Unlike the encoder-decoder architecture, it does not have an explicit encoder and encodes information implicitly in the hidden state of the decoder, updated at each step of the generation process.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.practicalai.io/understanding-transformer-model-architectures/#:~:text=Encoder|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeconvolutionalNetwork -->

    <Class rdf:about="https://w3id.org/aio/DeconvolutionalNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Deconvolutional networks allow unsupervised construction of hierarchical image representations for tasks such as denoising and feature extraction for object recognition.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Kernel, Convolutional/Pool, Output</rdfs:comment>
        <rdfs:label>Deconvolutional Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeconvolutionalNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Deconvolutional networks allow unsupervised construction of hierarchical image representations for tasks such as denoising and feature extraction for object recognition.</annotatedTarget>
        <oboInOwl:hasDbXref>https://ieeexplore.ieee.org/document/5539957|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepActiveLearning -->

    <Class rdf:about="https://w3id.org/aio/DeepActiveLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Combining deep learning and active learning to maximize model performance gain while annotating the fewest samples possible.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DeepAL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Deep Active Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepActiveLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Combining deep learning and active learning to maximize model performance gain while annotating the fewest samples possible.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/pdf/2009.00236.pdf|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepBeliefNetwork -->

    <Class rdf:about="https://w3id.org/aio/DeepBeliefNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UnsupervisedPretrainedNetwork"/>
        <obo:IAO_0000115>A deep belief network (DBN) is a generative graphical model composed of multiple layers of latent variables, learning to probabilistically reconstruct inputs and perform classification.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DBN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Backfed Input, Probabilistic Hidden, Hidden, Matched Output-Input</rdfs:comment>
        <rdfs:label>Deep Belief Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepBeliefNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A deep belief network (DBN) is a generative graphical model composed of multiple layers of latent variables, learning to probabilistically reconstruct inputs and perform classification.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Deep_belief_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepConvolutionalInverseGraphicsNetwork -->

    <Class rdf:about="https://w3id.org/aio/DeepConvolutionalInverseGraphicsNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AutoEncoderNetwork"/>
        <obo:IAO_0000115>A deep convolutional inverse graphics network (DC-IGN) learns interpretable image representations disentangled for transformations like out-of-plane rotations and lighting variations. It consists of convolution and de-convolution layers and is trained using the stochastic gradient variational Bayes (SGVB) algorithm.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DCIGN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Kernel, Convolutional/Pool, Probabilistic Hidden, Convolutional/Pool, Kernel, Output</rdfs:comment>
        <rdfs:label>Deep Convolutional Inverse Graphics Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepConvolutionalInverseGraphicsNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A deep convolutional inverse graphics network (DC-IGN) learns interpretable image representations disentangled for transformations like out-of-plane rotations and lighting variations. It consists of convolution and de-convolution layers and is trained using the stochastic gradient variational Bayes (SGVB) algorithm.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepConvolutionalNetwork -->

    <Class rdf:about="https://w3id.org/aio/DeepConvolutionalNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A deep convolutional network (CNN) is an artificial neural network used to analyze visual imagery, utilizing shared-weight architecture and translation-equivariant feature maps.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>CNN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>ConvNet</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Convolutional Neural Network</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>DCN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Kernel, Convolutional/Pool, Hidden, Output</rdfs:comment>
        <rdfs:label>Deep Convolutional Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepConvolutionalNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A deep convolutional network (CNN) is an artificial neural network used to analyze visual imagery, utilizing shared-weight architecture and translation-equivariant feature maps.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Convolutional_neural_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepFeed-ForwardNetwork -->

    <Class rdf:about="https://w3id.org/aio/DeepFeed-ForwardNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A deep feedforward neural network processes information in one direction—from input nodes through hidden nodes to output nodes—without cycles or loops.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DFF</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MLP</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Multilayer Perceptoron</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>Deep Feed-Forward Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepFeed-ForwardNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A deep feedforward neural network processes information in one direction—from input nodes through hidden nodes to output nodes—without cycles or loops.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Feedforward_neural_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepFeedForward -->

    <Class rdf:about="https://w3id.org/aio/DeepFeedForward"/>
    


    <!-- https://w3id.org/aio/DeepNeuralNetwork -->

    <Class rdf:about="https://w3id.org/aio/DeepNeuralNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ArtificialNeuralNetwork"/>
        <obo:IAO_0000115>A deep neural network (DNN) is a type of artificial neural network (ANN) characterized by multiple hidden layers between the input and output layers. Each layer consists of interconnected neurons that process and transmit information. DNNs can model complex patterns and representations in data through their hierarchical structure, where each layer extracts increasingly abstract features from the input. DNNs are widely used in various applications, including image and speech recognition, natural language processing, and more, due to their ability to learn and generalize from large amounts of data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DNN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Deep Neural Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A deep neural network (DNN) is a type of artificial neural network (ANN) characterized by multiple hidden layers between the input and output layers. Each layer consists of interconnected neurons that process and transmit information. DNNs can model complex patterns and representations in data through their hierarchical structure, where each layer extracts increasingly abstract features from the input. DNNs are widely used in various applications, including image and speech recognition, natural language processing, and more, due to their ability to learn and generalize from large amounts of data.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeepTransferLearning -->

    <Class rdf:about="https://w3id.org/aio/DeepTransferLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Relaxing the hypothesis that training data must be independent and identically distributed (i.i.d.) with test data to address insufficient training data.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Deep Transfer Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeepTransferLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Relaxing the hypothesis that training data must be independent and identically distributed (i.i.d.) with test data to address insufficient training data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/1808.01974|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DenoisingAutoEncoder -->

    <Class rdf:about="https://w3id.org/aio/DenoisingAutoEncoder">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AutoEncoderNetwork"/>
        <obo:IAO_0000115>Denoising autoencoders (DAEs) are neural networks trained to reconstruct the original undistorted input from a partially corrupted input, aiming to clean or denoise the corrupted input.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DAE</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Denoising Autoencoder</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Noisy Input, Hidden, Matched Output-Input</rdfs:comment>
        <rdfs:label>Denoising Auto Encoder</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DenoisingAutoEncoder"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Denoising autoencoders (DAEs) are neural networks trained to reconstruct the original undistorted input from a partially corrupted input, aiming to clean or denoise the corrupted input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.1145/1390156.1390294|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DenseFeaturesLayer -->

    <Class rdf:about="https://w3id.org/aio/DenseFeaturesLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that produces a dense Tensor based on given feature_columns. Generally a single example in training data is described with FeatureColumns. At the first layer of the model, this column oriented data should be converted to a single Tensor. This layer can be called multiple times with different features. This is the V2 version of this layer that uses name_scopes to create variables instead of variable_scopes. But this approach currently lacks support for partitioned variables. In that case, use the V1 version instead.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>DenseFeatures Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DenseFeaturesLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that produces a dense Tensor based on given feature_columns. Generally a single example in training data is described with FeatureColumns. At the first layer of the model, this column oriented data should be converted to a single Tensor. This layer can be called multiple times with different features. This is the V2 version of this layer that uses name_scopes to create variables instead of variable_scopes. But this approach currently lacks support for partitioned variables. In that case, use the V1 version instead.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/DenseFeatures</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DenseLayer -->

    <Class rdf:about="https://w3id.org/aio/DenseLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Just your regular densely-connected NN layer.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Dense Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DenseLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Just your regular densely-connected NN layer.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DeploymentBias -->

    <Class rdf:about="https://w3id.org/aio/DeploymentBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/GroupBias"/>
        <obo:IAO_0000115>Arises when systems are used as decision aids for humans, since the human intermediary may act on predictions in ways that are typically not modeled in the system. However, it is still individuals using the deployed system.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Deployment Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DeploymentBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Arises when systems are used as decision aids for humans, since the human intermediary may act on predictions in ways that are typically not modeled in the system. However, it is still individuals using the deployed system.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DepthwiseConv1DLayer -->

    <Class rdf:about="https://w3id.org/aio/DepthwiseConv1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>Depthwise 1D convolution. Depthwise convolution is a type of convolution in which each input channel is convolved with a different kernel (called a depthwise kernel). You can understand depthwise convolution as the first step in a depthwise separable convolution. It is implemented via the following steps: Split the input into individual channels. Convolve each channel with an individual depthwise kernel with depth_multiplier output channels. Concatenate the convolved outputs along the channels axis. Unlike a regular 1D convolution, depthwise convolution does not mix information across different input channels. The depth_multiplier argument determines how many filter are applied to one input channel. As such, it controls the amount of output channels that are generated per input channel in the depthwise step.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>DepthwiseConv1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DepthwiseConv1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Depthwise 1D convolution. Depthwise convolution is a type of convolution in which each input channel is convolved with a different kernel (called a depthwise kernel). You can understand depthwise convolution as the first step in a depthwise separable convolution. It is implemented via the following steps: Split the input into individual channels. Convolve each channel with an individual depthwise kernel with depth_multiplier output channels. Concatenate the convolved outputs along the channels axis. Unlike a regular 1D convolution, depthwise convolution does not mix information across different input channels. The depth_multiplier argument determines how many filter are applied to one input channel. As such, it controls the amount of output channels that are generated per input channel in the depthwise step.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DepthwiseConv2DLayer -->

    <Class rdf:about="https://w3id.org/aio/DepthwiseConv2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>Depthwise 2D convolution.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>DepthwiseConv2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DepthwiseConv2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Depthwise 2D convolution.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DetectionBias -->

    <Class rdf:about="https://w3id.org/aio/DetectionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Systematic differences between groups in how outcomes are determined, potentially over- or underestimating effect size.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Detection Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DetectionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic differences between groups in how outcomes are determined, potentially over- or underestimating effect size.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DialogueLLM -->

    <Class rdf:about="https://w3id.org/aio/DialogueLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A dialogue LLM is optimized for engaging in multi-turn conversations, understanding context, and generating relevant, coherent responses continuously over many dialogue turns.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Dialogue Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>conversational AI</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>multi-turn dialogue</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Dialogue LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DialogueLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A dialogue LLM is optimized for engaging in multi-turn conversations, understanding context, and generating relevant, coherent responses continuously over many dialogue turns.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DifferentiableLLM -->

    <Class rdf:about="https://w3id.org/aio/DifferentiableLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A differentiable LLM has an architecture amenable to full end-to-end training via backpropagation, without relying on teacher forcing or unlikelihood training objectives.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Differentiable Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>end-to-end training</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>fully backpropagable</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Differentiable LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DifferentiableLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A differentiable LLM has an architecture amenable to full end-to-end training via backpropagation, without relying on teacher forcing or unlikelihood training objectives.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DimensionalityReduction -->

    <Class rdf:about="https://w3id.org/aio/DimensionalityReduction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UnsupervisedLearning"/>
        <obo:IAO_0000115>The process of transforming data from a high-dimensional space into a lower-dimensional space while retaining meaningful properties of the original data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Dimension Reduction</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Dimensionality Reduction</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DimensionalityReduction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of transforming data from a high-dimensional space into a lower-dimensional space while retaining meaningful properties of the original data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Dimensionality_reduction|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DiscretizationLayer -->

    <Class rdf:about="https://w3id.org/aio/DiscretizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NumericalFeaturesPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which buckets continuous features by ranges.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Discretization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DiscretizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which buckets continuous features by ranges.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Discretization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Distillation -->

    <Class rdf:about="https://w3id.org/aio/Distillation">
        <obo:IAO_0000115>The process of training a smaller model to replicate the behavior of a larger model, aiming to compress the knowledge into a more compact form without significant loss of performance.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Purification</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Refining</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Knowledge compression</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Teacher-student model</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Distillation</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Distillation"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of training a smaller model to replicate the behavior of a larger model, aiming to compress the knowledge into a more compact form without significant loss of performance.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.48550/arXiv.2105.13093|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Domain-AdaptedLLM -->

    <Class rdf:about="https://w3id.org/aio/Domain-AdaptedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A domain-adapted LLM is pre-trained on a broad corpus and then fine-tuned on domain-specific data to specialize its capabilities for particular domains or applications, like scientific literature or code generation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Domain-Adapted Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>domain robustness</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>transfer learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Domain-Adapted LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Domain-AdaptedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A domain-adapted LLM is pre-trained on a broad corpus and then fine-tuned on domain-specific data to specialize its capabilities for particular domains or applications, like scientific literature or code generation.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DotLayer -->

    <Class rdf:about="https://w3id.org/aio/DotLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Layer that computes a dot product between samples in two tensors. E.g. if applied to a list of two tensors a and b of shape (batch_size, n), the output will be a tensor of shape (batch_size, 1) where each entry i will be the dot product between a[i] and b[i].</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Dot Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DotLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that computes a dot product between samples in two tensors. E.g. if applied to a list of two tensors a and b of shape (batch_size, n), the output will be a tensor of shape (batch_size, 1) where each entry i will be the dot product between a[i] and b[i].</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DropoutLayer -->

    <Class rdf:about="https://w3id.org/aio/DropoutLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Applies Dropout to the input. The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged. Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference. When using model.fit, training will be appropriately set to True automatically, and in other contexts, you can set the kwarg explicitly to True when calling the layer. (This is in contrast to setting trainable=False for a Dropout layer. trainable does not affect the layer&apos;s behavior, as Dropout does not have any variables/weights that can be frozen during training.)</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Dropout Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DropoutLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Dropout to the input. The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged. Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference. When using model.fit, training will be appropriately set to True automatically, and in other contexts, you can set the kwarg explicitly to True when calling the layer. (This is in contrast to setting trainable=False for a Dropout layer. trainable does not affect the layer&apos;s behavior, as Dropout does not have any variables/weights that can be frozen during training.)</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Dunning-KrugerEffectBias -->

    <Class rdf:about="https://w3id.org/aio/Dunning-KrugerEffectBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/CognitiveBias"/>
        <obo:IAO_0000115>The tendency of people with low ability in an area to overestimate their self-assessed ability, often measured by comparing self-assessment with objective performance.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Dunning-Kruger Effect</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Dunning-Kruger Effect Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Dunning-KrugerEffectBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The tendency of people with low ability in an area to overestimate their self-assessed ability, often measured by comparing self-assessment with objective performance.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ELUFunction -->

    <Class rdf:about="https://w3id.org/aio/ELUFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>The exponential linear unit (ELU) with alpha &gt; 0 is: x if x &gt; 0 and alpha * (exp(x) - 1) if x &lt; 0 The ELU hyperparameter alpha controls the value to which an ELU saturates for negative net inputs. ELUs diminish the vanishing gradient effect. ELUs have negative values which pushes the mean of the activations closer to zero. Mean activations that are closer to zero enable faster Learning as they bring the gradient closer to the natural gradient. ELUs saturate to a negative value when the argument gets smaller. Saturation means a small derivative which decreases the variation and the information that is propagated to the next layer.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ELU</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Exponential Linear Unit</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>ELU Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ELUFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The exponential linear unit (ELU) with alpha &gt; 0 is: x if x &gt; 0 and alpha * (exp(x) - 1) if x &lt; 0 The ELU hyperparameter alpha controls the value to which an ELU saturates for negative net inputs. ELUs diminish the vanishing gradient effect. ELUs have negative values which pushes the mean of the activations closer to zero. Mean activations that are closer to zero enable faster Learning as they bring the gradient closer to the natural gradient. ELUs saturate to a negative value when the argument gets smaller. Saturation means a small derivative which decreases the variation and the information that is propagated to the next layer.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/elu</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ELULayer -->

    <Class rdf:about="https://w3id.org/aio/ELULayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <obo:IAO_0000115>Exponential Linear Unit.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ELU Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ELULayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Exponential Linear Unit.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ELU</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EchoStateNetwork -->

    <Class rdf:about="https://w3id.org/aio/EchoStateNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentNeuralNetwork"/>
        <obo:IAO_0000115>An echo state network (ESN) is a type of reservoir computer with a recurrent neural network and a sparsely connected hidden layer, learning output neuron weights to produce temporal patterns.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ESN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Recurrent, Output</rdfs:comment>
        <rdfs:label>Echo State Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EchoStateNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An echo state network (ESN) is a type of reservoir computer with a recurrent neural network and a sparsely connected hidden layer, learning output neuron weights to produce temporal patterns.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Echo_state_network#:~:text=The%20echo%20state%20network%20(ESN,are%20fixed%20and%20randomly%20assigned|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EcologicalFallacyBias -->

    <Class rdf:about="https://w3id.org/aio/EcologicalFallacyBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias occurring when an inference about an individual is made based on their group membership.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Ecological Fallacy</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Ecological Fallacy Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EcologicalFallacyBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias occurring when an inference about an individual is made based on their group membership.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EmbeddingLayer -->

    <Class rdf:about="https://w3id.org/aio/EmbeddingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Turns positive integers (indexes) into dense vectors of fixed size.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Embedding Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EmbeddingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Turns positive integers (indexes) into dense vectors of fixed size.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EmbodiedLLM -->

    <Class rdf:about="https://w3id.org/aio/EmbodiedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An embodied LLM integrates language with other modalities like vision, audio, and robotics to enable grounded language understanding in real-world environments.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Embodied Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>multimodal grounding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Embodied LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EmbodiedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An embodied LLM integrates language with other modalities like vision, audio, and robotics to enable grounded language understanding in real-world environments.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EmergentBias -->

    <Class rdf:about="https://w3id.org/aio/EmergentBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Bias resulting from the use and reliance on algorithms across new or unanticipated contexts.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Emergent Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EmergentBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias resulting from the use and reliance on algorithms across new or unanticipated contexts.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Encoder-DecoderLLM -->

    <Class rdf:about="https://w3id.org/aio/Encoder-DecoderLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>The original transformer architecture introduced in the &quot;Attention Is All You Need&quot; paper. The encoder processes the input sequence to generate a hidden representation summarizing the input information, while the decoder uses this hidden representation to generate the desired output sequence. The encoder and decoder a</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Encoder-Decoder LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Encoder-DecoderLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The original transformer architecture introduced in the &quot;Attention Is All You Need&quot; paper. The encoder processes the input sequence to generate a hidden representation summarizing the input information, while the decoder uses this hidden representation to generate the desired output sequence. The encoder and decoder a</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.practicalai.io/understanding-transformer-model-architectures/#:~:text=Encoder|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EncoderLLM -->

    <Class rdf:about="https://w3id.org/aio/EncoderLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An encoder-only architecture that encodes the input sequence into a fixed-length representation, which is then used as input to a classifier or regressor for prediction. The model has a pre-trained general-purpose encoder that requires fine-tuning for specific tasks.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Encoder LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EncoderLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An encoder-only architecture that encodes the input sequence into a fixed-length representation, which is then used as input to a classifier or regressor for prediction. The model has a pre-trained general-purpose encoder that requires fine-tuning for specific tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.practicalai.io/understanding-transformer-model-architectures/#:~:text=Encoder|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Energy-BasedLLM -->

    <Class rdf:about="https://w3id.org/aio/Energy-BasedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An energy-based LLM models the explicit probability density over token sequences using an energy function, rather than an autoregressive factorization. This can improve modeling of long-range dependencies and global coherence.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Energy-Based Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>energy scoring</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>explicit density modeling</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Energy-Based LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Energy-BasedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An energy-based LLM models the explicit probability density over token sequences using an energy function, rather than an autoregressive factorization. This can improve modeling of long-range dependencies and global coherence.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EnsembleLearning -->

    <Class rdf:about="https://w3id.org/aio/EnsembleLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that use multiple learning algorithms to achieve better predictive performance than any of the constituent algorithms alone.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Ensemble Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EnsembleLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that use multiple learning algorithms to achieve better predictive performance than any of the constituent algorithms alone.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Ensemble_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ErrorPropagationBias -->

    <Class rdf:about="https://w3id.org/aio/ErrorPropagationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProcessingBias"/>
        <obo:IAO_0000115>The effect of variables&apos; uncertainties (or errors, more specifically random errors) on the uncertainty of a function based on them.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Error Propagation</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Error Propagation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ErrorPropagationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The effect of variables&apos; uncertainties (or errors, more specifically random errors) on the uncertainty of a function based on them.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EthicalLLM -->

    <Class rdf:about="https://w3id.org/aio/EthicalLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An ethical LLM is trained to uphold certain ethical principles, values, or rules in its language generation to increase safety and trustworthiness.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Ethical Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>constituitional AI</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>value alignment</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Ethical LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EthicalLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An ethical LLM is trained to uphold certain ethical principles, values, or rules in its language generation to increase safety and trustworthiness.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EvaluationBias -->

    <Class rdf:about="https://w3id.org/aio/EvaluationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias arising when testing populations do not equally represent user populations or when inappropriate performance metrics are used.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Evaluation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EvaluationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when testing populations do not equally represent user populations or when inappropriate performance metrics are used.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/EvolutionaryLLM -->

    <Class rdf:about="https://w3id.org/aio/EvolutionaryLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An evolutionary LLM applies principles of evolutionary computation to optimize its structure and parameters, evolving over time to improve performance.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Evolutionary Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>evolutionary algorithms</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>genetic programming</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Evolutionary LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/EvolutionaryLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An evolutionary LLM applies principles of evolutionary computation to optimize its structure and parameters, evolving over time to improve performance.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ExclusionBias -->

    <Class rdf:about="https://w3id.org/aio/ExclusionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias occurring when specific groups of user populations are excluded from testing and analysis.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Exclusion Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ExclusionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias occurring when specific groups of user populations are excluded from testing and analysis.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ExplainableLLM -->

    <Class rdf:about="https://w3id.org/aio/ExplainableLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An explainable LLM is designed to provide insights into its decision-making process, making it easier for users to understand and trust the model&apos;s outputs. It incorporates mechanisms for interpreting and explaining its predictions in human-understandable terms.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Explainable Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>XAI LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>interpretability</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>model understanding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Explainable LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ExplainableLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An explainable LLM is designed to provide insights into its decision-making process, making it easier for users to understand and trust the model&apos;s outputs. It incorporates mechanisms for interpreting and explaining its predictions in human-understandable terms.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ExponentialFunction -->

    <Class rdf:about="https://w3id.org/aio/ExponentialFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>The exponential function is a mathematical function denoted by f(x)=exp or e^{x}.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Exponential Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ExponentialFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The exponential function is a mathematical function denoted by f(x)=exp or e^{x}.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/exponential</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ExtremeLearningMachine -->

    <Class rdf:about="https://w3id.org/aio/ExtremeLearningMachine">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/FeedbackNetwork"/>
        <obo:IAO_0000115>Extreme learning machines are feedforward neural networks with randomly assigned hidden node parameters that are not updated, learning output weights in a single step.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ELM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>Extreme Learning Machine</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ExtremeLearningMachine"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Extreme learning machines are feedforward neural networks with randomly assigned hidden node parameters that are not updated, learning output weights in a single step.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Extreme_Learning_machine|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FactoredLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/FactoredLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A factored language model views each word as a vector of multiple factors, such as part-of-speech, morphology, and semantics, to improve language modeling.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Factorized Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Factored Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FactoredLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A factored language model views each word as a vector of multiple factors, such as part-of-speech, morphology, and semantics, to improve language modeling.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Factored_language_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FactorizedLLM -->

    <Class rdf:about="https://w3id.org/aio/FactorizedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A factorized LLM decomposes the full language modeling task into multiple sub-components or experts that each focus on a subset of the information, enabling more efficient scaling.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Factorized Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Factorized Learning Assisted with Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Conditional masking</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Product of experts</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Factorized LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FactorizedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A factorized LLM decomposes the full language modeling task into multiple sub-components or experts that each focus on a subset of the information, enabling more efficient scaling.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.48550/arXiv.2403.12556|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FeatureExtraction -->

    <Class rdf:about="https://w3id.org/aio/FeatureExtraction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DataEnhancement"/>
        <obo:IAO_0000115>The process of transforming raw data into a set of measurable characteristics that can be used as input for machine learning algorithms, enhancing the ability to make accurate predictions.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Attribute Extraction</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Feature Isolation</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Semantic embeddings</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Syntactic information</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Feature Extraction</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FeatureExtraction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of transforming raw data into a set of measurable characteristics that can be used as input for machine learning algorithms, enhancing the ability to make accurate predictions.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FederatedLLM -->

    <Class rdf:about="https://w3id.org/aio/FederatedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A federated LLM is trained in a decentralized manner across multiple devices or silos, without directly sharing private data. This enables collaborative training while preserving data privacy and security.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Federated Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>decentralized training</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>privacy-preserving</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Federated LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FederatedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A federated LLM is trained in a decentralized manner across multiple devices or silos, without directly sharing private data. This enables collaborative training while preserving data privacy and security.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FederatedLearning -->

    <Class rdf:about="https://w3id.org/aio/FederatedLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Training an algorithm across multiple decentralized edge devices or servers holding local data samples without exchanging them.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Federated Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FederatedLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Training an algorithm across multiple decentralized edge devices or servers holding local data samples without exchanging them.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Federated_learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FeedbackLoopBias -->

    <Class rdf:about="https://w3id.org/aio/FeedbackLoopBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Effects occurring when an algorithm learns from user behavior and feeds that behavior back into the model.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Feedback Loop Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FeedbackLoopBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Effects occurring when an algorithm learns from user behavior and feeds that behavior back into the model.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FeedbackNetwork -->

    <Class rdf:about="https://w3id.org/aio/FeedbackNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ArtificialNeuralNetwork"/>
        <obo:IAO_0000115>A feedback network iteratively refines its representations based on feedback from previous iterations&apos; outputs.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>FBN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output, Hidden</rdfs:comment>
        <rdfs:label>Feedback Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FeedbackNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A feedback network iteratively refines its representations based on feedback from previous iterations&apos; outputs.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FixedEffectsModel -->

    <Class rdf:about="https://w3id.org/aio/FixedEffectsModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A statistical model in which the model parameters are fixed or non-random quantities.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>FEM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Fixed Effects Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FixedEffectsModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A statistical model in which the model parameters are fixed or non-random quantities.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Fixed_effects_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FlattenLayer -->

    <Class rdf:about="https://w3id.org/aio/FlattenLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Flattens the input. Does not affect the batch size.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Flatten Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FlattenLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Flattens the input. Does not affect the batch size.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FractionalMaxPool2DLayer -->

    <Class rdf:about="https://w3id.org/aio/FractionalMaxPool2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 2D fractional max pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>FractionalMaxPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>FractionalMaxPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>FractionalMaxPool2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FractionalMaxPool2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 2D fractional max pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FractionalMaxPool3DLayer -->

    <Class rdf:about="https://w3id.org/aio/FractionalMaxPool3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 3D fractional max pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>FractionalMaxPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>FractionalMaxPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>FractionalMaxPool3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FractionalMaxPool3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 3D fractional max pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Function -->

    <Class rdf:about="https://w3id.org/aio/Function">
        <obo:IAO_0000115>A mathematical rule that gives the value of a dependent variable corresponding to specified values of one or more independent variables.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ClassSubset"/>
        <rdfs:label>Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Function"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A mathematical rule that gives the value of a dependent variable corresponding to specified values of one or more independent variables.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.sciencedirect.com/topics/mathematics/mathematical-function|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/FundingBias -->

    <Class rdf:about="https://w3id.org/aio/FundingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/GroupBias"/>
        <obo:IAO_0000115>Bias arising when biased results are reported to support or satisfy the funding agency or financial supporter of a research study.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Funding Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/FundingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when biased results are reported to support or satisfy the funding agency or financial supporter of a research study.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GELUFunction -->

    <Class rdf:about="https://w3id.org/aio/GELUFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>Gaussian error linear unit (GELU) computes x * P(X &lt;= x), where P(X) ~ N(0, 1). The (GELU) nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLU.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GELU</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Gaussian Error Linear Unit</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>GELU Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GELUFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Gaussian error linear unit (GELU) computes x * P(X &lt;= x), where P(X) ~ N(0, 1). The (GELU) nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLU.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/gelu</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GRUCellLayer -->

    <Class rdf:about="https://w3id.org/aio/GRUCellLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Cell class for the GRU layer. This class processes one step within the whole time sequence input, whereas tf.keras.layer.GRU processes the whole sequence.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GRUCell Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GRUCellLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Cell class for the GRU layer. This class processes one step within the whole time sequence input, whereas tf.keras.layer.GRU processes the whole sequence.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GRULayer -->

    <Class rdf:about="https://w3id.org/aio/GRULayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>Gated Recurrent Unit - Cho et al. 2014. Based on available runtime hardware and constraints, this layer will choose different implementations (cuDNN-based or pure-TensorFlow) to maximize the performance. If a GPU is available and all the arguments to the layer meet the requirement of the cuDNN kernel (see below for details), the layer will use a fast cuDNN implementation. The requirements to use the cuDNN implementation are: activation == tanh, recurrent_activation == sigmoid, recurrent_dropout == 0, unroll is False, use_bias is True, reset_after is True. Inputs, if use masking, are strictly right-padded. Eager execution is enabled in the outermost context. There are two variants of the GRU implementation. The default one is based on v3 and has reset gate applied to hidden state before matrix multiplication. The other one is based on original and has the order reversed. The second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for kernel and recurrent_kernel. To use this variant, set reset_after=True and recurrent_activation=&apos;sigmoid&apos;.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GRU Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GRULayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Gated Recurrent Unit - Cho et al. 2014. Based on available runtime hardware and constraints, this layer will choose different implementations (cuDNN-based or pure-TensorFlow) to maximize the performance. If a GPU is available and all the arguments to the layer meet the requirement of the cuDNN kernel (see below for details), the layer will use a fast cuDNN implementation. The requirements to use the cuDNN implementation are: activation == tanh, recurrent_activation == sigmoid, recurrent_dropout == 0, unroll is False, use_bias is True, reset_after is True. Inputs, if use masking, are strictly right-padded. Eager execution is enabled in the outermost context. There are two variants of the GRU implementation. The default one is based on v3 and has reset gate applied to hidden state before matrix multiplication. The other one is based on original and has the order reversed. The second variant is compatible with CuDNNGRU (GPU-only) and allows inference on CPU. Thus it has separate biases for kernel and recurrent_kernel. To use this variant, set reset_after=True and recurrent_activation=&apos;sigmoid&apos;.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GatedRecurrentUnit -->

    <Class rdf:about="https://w3id.org/aio/GatedRecurrentUnit">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LongShortTermMemory"/>
        <obo:IAO_0000115>Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, similar to LSTMs but with fewer parameters and no output gate.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GRU</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Memory Cell, Output</rdfs:comment>
        <rdfs:label>Gated Recurrent Unit</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GatedRecurrentUnit"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, similar to LSTMs but with fewer parameters and no output gate.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Gated_recurrent_unit|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GaussianDropoutLayer -->

    <Class rdf:about="https://w3id.org/aio/GaussianDropoutLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GaussianDropout Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GaussianDropoutLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianDropout</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GaussianNoiseLayer -->

    <Class rdf:about="https://w3id.org/aio/GaussianNoiseLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Apply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs. As it is a regularization layer, it is only active at training time.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GaussianNoise Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GaussianNoiseLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Apply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs. As it is a regularization layer, it is only active at training time.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GaussianNoise</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GeneralizedFew-shotLearning -->

    <Class rdf:about="https://w3id.org/aio/GeneralizedFew-shotLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Learning novel classes from few samples per class, preventing catastrophic forgetting of base classes and ensuring classifier calibration.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GFSL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Generalized Few-shot Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GeneralizedFew-shotLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Learning novel classes from few samples per class, preventing catastrophic forgetting of base classes and ensuring classifier calibration.</annotatedTarget>
        <oboInOwl:hasDbXref>https://paperswithcode.com/paper/generalized-and-incremental-few-shot-learning/review/|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GeneralizedLinearModel -->

    <Class rdf:about="https://w3id.org/aio/GeneralizedLinearModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A model that generalizes linear regression by relating the linear model to the response variable via a link function and allowing the variance of each measurement to be a function of its predicted value.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GLM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Generalized Linear Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GeneralizedLinearModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A model that generalizes linear regression by relating the linear model to the response variable via a link function and allowing the variance of each measurement to be a function of its predicted value.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Generalized_linear_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GenerativeAdversarialNetwork -->

    <Class rdf:about="https://w3id.org/aio/GenerativeAdversarialNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UnsupervisedPretrainedNetwork"/>
        <obo:IAO_0000115>A generative adversarial network (GAN) is a machine learning framework where two neural networks contest in a game to generate new data with the same statistics as the training set.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GAN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Backfed Input, Hidden, Matched Output-Input, Hidden, Matched Output-Input</rdfs:comment>
        <rdfs:label>Generative Adversarial Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GenerativeAdversarialNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A generative adversarial network (GAN) is a machine learning framework where two neural networks contest in a game to generate new data with the same statistics as the training set.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Generative_adversarial_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GenerativeAdversarialNetwork-AugmentedLLM -->

    <Class rdf:about="https://w3id.org/aio/GenerativeAdversarialNetwork-AugmentedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A GAN-augmented LLM incorporates a generative adversarial network (GAN) into its training process, using a discriminator network to provide a signal for generating more realistic and coherent text. This adversarial training can improve the quality and diversity of generated text.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GAN-Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Generative Adversarial Network-Augmented Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>adversarial training</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>text generation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Generative Adversarial Network-Augmented LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GenerativeAdversarialNetwork-AugmentedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A GAN-augmented LLM incorporates a generative adversarial network (GAN) into its training process, using a discriminator network to provide a signal for generating more realistic and coherent text. This adversarial training can improve the quality and diversity of generated text.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GenerativeCommonsenseLLM -->

    <Class rdf:about="https://w3id.org/aio/GenerativeCommonsenseLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A generative commonsense LLM is trained to understand and model basic physics, causality, and common sense about how the real world works.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Generative Commonsense Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>World Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>causal modeling</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>physical reasoning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Generative Commonsense LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GenerativeCommonsenseLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A generative commonsense LLM is trained to understand and model basic physics, causality, and common sense about how the real world works.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2306.12672|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GenerativeLanguageInterface -->

    <Class rdf:about="https://w3id.org/aio/GenerativeLanguageInterface">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A generative language interface enables users to engage in an interactive dialogue with an LLM, providing feedback to guide and refine the generated outputs iteratively.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Generative Language Interface</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Interactive generation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Generative Language Interface</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GenerativeLanguageInterface"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A generative language interface enables users to engage in an interactive dialogue with an LLM, providing feedback to guide and refine the generated outputs iteratively.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GlobalAveragePooling1DLayer -->

    <Class rdf:about="https://w3id.org/aio/GlobalAveragePooling1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Global average pooling operation for temporal data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GlobalAvgPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>GlobalAvgPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GlobalAveragePooling1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GlobalAveragePooling1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Global average pooling operation for temporal data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GlobalAveragePooling2DLayer -->

    <Class rdf:about="https://w3id.org/aio/GlobalAveragePooling2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Global average pooling operation for spatial data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GlobalAvgPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>GlobalAvgPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GlobalAveragePooling2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GlobalAveragePooling2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Global average pooling operation for spatial data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GlobalAveragePooling3DLayer -->

    <Class rdf:about="https://w3id.org/aio/GlobalAveragePooling3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Global Average pooling operation for 3D data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GlobalAvgPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>GlobalAvgPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GlobalAveragePooling3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GlobalAveragePooling3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Global Average pooling operation for 3D data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GlobalMaxPooling1DLayer -->

    <Class rdf:about="https://w3id.org/aio/GlobalMaxPooling1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Global max pooling operation for 1D temporal data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GlobalMaxPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>GlobalMaxPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GlobalMaxPooling1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GlobalMaxPooling1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Global max pooling operation for 1D temporal data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GlobalMaxPooling2DLayer -->

    <Class rdf:about="https://w3id.org/aio/GlobalMaxPooling2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Global max pooling operation for spatial data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GlobalMaxPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>GlobalMaxPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GlobalMaxPooling2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GlobalMaxPooling2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Global max pooling operation for spatial data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GlobalMaxPooling3DLayer -->

    <Class rdf:about="https://w3id.org/aio/GlobalMaxPooling3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Global Max pooling operation for 3D data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GlobalMaxPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>GlobalMaxPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GlobalMaxPooling3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GlobalMaxPooling3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Global Max pooling operation for 3D data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GraphConvolutionalNetwork -->

    <Class rdf:about="https://w3id.org/aio/GraphConvolutionalNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A graph convolutional network (GCN) operates directly on graph structures, utilizing their structural information for tasks like node classification and graph clustering.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GCN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Hidden, Output</rdfs:comment>
        <rdfs:label>Graph Convolutional Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GraphConvolutionalNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A graph convolutional network (GCN) operates directly on graph structures, utilizing their structural information for tasks like node classification and graph clustering.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/1609.02907|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GraphConvolutionalPolicyNetwork -->

    <Class rdf:about="https://w3id.org/aio/GraphConvolutionalPolicyNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/GraphConvolutionalNetwork"/>
        <obo:IAO_0000115>A graph convolutional policy network (GCPN) generates goal-directed graphs using a graph convolutional network and reinforcement learning, optimizing for domain-specific rewards and adversarial loss</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GPCN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Hidden, Policy, Output</rdfs:comment>
        <rdfs:label>Graph Convolutional Policy Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GraphConvolutionalPolicyNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A graph convolutional policy network (GCPN) generates goal-directed graphs using a graph convolutional network and reinforcement learning, optimizing for domain-specific rewards and adversarial loss</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/1806.02473|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GraphLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/GraphLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A graph language model operates over structured inputs or outputs represented as graphs, enabling reasoning over explicit relational knowledge representations during language tasks.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Graph LM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Structured representations</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Graph Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GraphLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A graph language model operates over structured inputs or outputs represented as graphs, enabling reasoning over explicit relational knowledge representations during language tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2401.07105|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GroupBias -->

    <Class rdf:about="https://w3id.org/aio/GroupBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/HumanBias"/>
        <obo:IAO_0000115>Favoring members of one&apos;s in-group over out-group members, expressed in evaluation, resource allocation, and other ways.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>In-group Favoritism</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>In-group bias</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>In-group preference</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>In-group–out-group Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Intergroup bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Group Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GroupBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Favoring members of one&apos;s in-group over out-group members, expressed in evaluation, resource allocation, and other ways.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/In-group_favoritism|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GroupNormLayer -->

    <Class rdf:about="https://w3id.org/aio/GroupNormLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Applies Group Normalization over a mini-batch of inputs as described in the paper Group Normalization</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GroupNorm</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>GroupNorm Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GroupNormLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Group Normalization over a mini-batch of inputs as described in the paper Group Normalization</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GroupthinkBias -->

    <Class rdf:about="https://w3id.org/aio/GroupthinkBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/GroupBias"/>
        <obo:IAO_0000115>A psychological phenomenon where people in a group make non-optimal decisions due to a desire to conform or fear of dissent.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Groupthink</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Groupthink Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GroupthinkBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A psychological phenomenon where people in a group make non-optimal decisions due to a desire to conform or fear of dissent.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HardSigmoidFunction -->

    <Class rdf:about="https://w3id.org/aio/HardSigmoidFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>A faster approximation of the sigmoid activation. Piecewise linear approximation of the sigmoid function. Ref: &apos;https://en.wikipedia.org/wiki/Hard_sigmoid&apos;</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Hard Sigmoid Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HardSigmoidFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A faster approximation of the sigmoid activation. Piecewise linear approximation of the sigmoid function. Ref: &apos;https://en.wikipedia.org/wiki/Hard_sigmoid&apos;</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/hard_sigmoid</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HashingLayer -->

    <Class rdf:about="https://w3id.org/aio/HashingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which hashes and bins categorical features. This layer transforms categorical inputs to hashed output. It element-wise converts a ints or strings to ints in a fixed range. The stable hash function uses tensorflow::ops::Fingerprint to produce the same output consistently across all platforms. This layer uses FarmHash64 by default, which provides a consistent hashed output across different platforms and is stable across invocations, regardless of device and context, by mixing the input bits thoroughly. If you want to obfuscate the hashed output, you can also pass a random salt argument in the constructor. In that case, the layer will use the SipHash64 hash function, with the salt value serving as additional input to the hash function.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Hashing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HashingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which hashes and bins categorical features. This layer transforms categorical inputs to hashed output. It element-wise converts a ints or strings to ints in a fixed range. The stable hash function uses tensorflow::ops::Fingerprint to produce the same output consistently across all platforms. This layer uses FarmHash64 by default, which provides a consistent hashed output across different platforms and is stable across invocations, regardless of device and context, by mixing the input bits thoroughly. If you want to obfuscate the hashed output, you can also pass a random salt argument in the constructor. In that case, the layer will use the SipHash64 hash function, with the salt value serving as additional input to the hash function.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HiddenLayer -->

    <Class rdf:about="https://w3id.org/aio/HiddenLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output. In short, the hidden layers perform nonlinear transformations of the inputs entered into the network. Hidden layers vary depending on the function of the neural network, and similarly, the layers may vary depending on their associated weights.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Hidden Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HiddenLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A hidden layer is located between the input and output of the algorithm, in which the function applies weights to the inputs and directs them through an activation function as the output. In short, the hidden layers perform nonlinear transformations of the inputs entered into the network. Hidden layers vary depending on the function of the neural network, and similarly, the layers may vary depending on their associated weights.</annotatedTarget>
        <oboInOwl:hasDbXref>https://deepai.org/machine-Learning-glossary-and-terms/hidden-layer-machine-Learning</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HierarchicalClassification -->

    <Class rdf:about="https://w3id.org/aio/HierarchicalClassification">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Classification"/>
        <obo:IAO_0000115>Methods that group things according to a hierarchy.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Hierarchical Classification</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HierarchicalClassification"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that group things according to a hierarchy.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Hierarchical_classification|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HierarchicalClustering -->

    <Class rdf:about="https://w3id.org/aio/HierarchicalClustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Clustering"/>
        <obo:IAO_0000115>Methods that build a hierarchy of clusters.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>HCL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Hierarchical Clustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HierarchicalClustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that build a hierarchy of clusters.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Hierarchical_clustering|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HierarchicalLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/HierarchicalLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A hierarchical language model represents language at multiple levels of granularity, learning hierarchical representations that capture both low-level patterns and high-level abstractions.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Hierarchical LM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>multi-scale representations</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Hierarchical Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HierarchicalLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A hierarchical language model represents language at multiple levels of granularity, learning hierarchical representations that capture both low-level patterns and high-level abstractions.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.1016/j.ipm.2024.103698|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HistoricalBias -->

    <Class rdf:about="https://w3id.org/aio/HistoricalBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>Long-standing biases encoded in society over time, distinct from biases in historical description or the interpretation of history, such as viewing the larger world from a Western or European perspective.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Historical Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HistoricalBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Long-standing biases encoded in society over time, distinct from biases in historical description or the interpretation of history, such as viewing the larger world from a Western or European perspective.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HopfieldNetwork -->

    <Class rdf:about="https://w3id.org/aio/HopfieldNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SymmetricallyConnectedNetwork"/>
        <obo:IAO_0000115>A Hopfield network is a type of recurrent artificial neural network that serves as a content-addressable (&quot;associative&quot;) memory system. It uses binary threshold nodes or continuous variables to store and recall memory patterns, providing a model for understanding human memory.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>HN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Ising model of a neural network</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Ising–Lenz–Little model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Backfed input</rdfs:comment>
        <rdfs:label>Hopfield Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HopfieldNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A Hopfield network is a type of recurrent artificial neural network that serves as a content-addressable (&quot;associative&quot;) memory system. It uses binary threshold nodes or continuous variables to store and recall memory patterns, providing a model for understanding human memory.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Hopfield_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HostileAttributionBias -->

    <Class rdf:about="https://w3id.org/aio/HostileAttributionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Bias where individuals perceive benign or ambiguous behaviors as hostile.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Hostile Attribution Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HostileAttributionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias where individuals perceive benign or ambiguous behaviors as hostile.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Interpretive_bias|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HumanBias -->

    <Class rdf:about="https://w3id.org/aio/HumanBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>Systematic errors in human thought based on heuristic principles, leading to simplified judgmental operations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Human Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HumanBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic errors in human thought based on heuristic principles, leading to simplified judgmental operations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/HumanReportingBias -->

    <Class rdf:about="https://w3id.org/aio/HumanReportingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>When users rely on automation as a heuristic replacement for their own information seeking and processing.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Human Reporting Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/HumanReportingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>When users rely on automation as a heuristic replacement for their own information seeking and processing.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ImageAugmentationLayer -->

    <Class rdf:about="https://w3id.org/aio/ImageAugmentationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that performs image data preprocessing augmentations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Image Augmentation Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ImageAugmentationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that performs image data preprocessing augmentations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/guides/preprocessing_layers/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ImagePreprocessingLayer -->

    <Class rdf:about="https://w3id.org/aio/ImagePreprocessingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that performs image data preprocessing operations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Image Preprocessing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ImagePreprocessingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that performs image data preprocessing operations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/guides/preprocessing_layers/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ImplicitBias -->

    <Class rdf:about="https://w3id.org/aio/ImplicitBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Unconscious beliefs, attitudes, feelings, associations, or stereotypes that affect information processing, decision-making, and actions.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Confirmatory Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Implicit Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ImplicitBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Unconscious beliefs, attitudes, feelings, associations, or stereotypes that affect information processing, decision-making, and actions.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ImplicitLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/ImplicitLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>An implicit language model uses an energy function to score entire sequences instead of factorizing probabilities autoregressively, better capturing global properties and long-range dependencies.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Implicit LM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Energy-based models</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Token-level scoring</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Implicit Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ImplicitLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An implicit language model uses an energy function to score entire sequences instead of factorizing probabilities autoregressively, better capturing global properties and long-range dependencies.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/pdf/2303.16189|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/IncremenetalFew-shotLearning -->

    <Class rdf:about="https://w3id.org/aio/IncremenetalFew-shotLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Training a network on a base set of classes and then presenting it with novel classes, each with few labeled examples.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>IFSL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Incremenetal Few-shot Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/IncremenetalFew-shotLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Training a network on a base set of classes and then presenting it with novel classes, each with few labeled examples.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/1810.07218|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/IndividualBias -->

    <Class rdf:about="https://w3id.org/aio/IndividualBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>A persistent point of view or limited list of such points of view applied by an individual, such as &quot;parent,&quot; &quot;academic,&quot; or &quot;professional.&quot;</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Individual Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A persistent point of view or limited list of such points of view applied by an individual, such as &quot;parent,&quot; &quot;academic,&quot; or &quot;professional.&quot;</annotatedTarget>
        <oboInOwl:hasDbXref>https://develop.consumerium.org/wiki/Individual_bias|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InheritedBias -->

    <Class rdf:about="https://w3id.org/aio/InheritedBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProcessingBias"/>
        <obo:IAO_0000115>Bias arising when machine learning applications generate inputs for other machine learning algorithms, passing on any existing bias.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Inherited Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InheritedBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when machine learning applications generate inputs for other machine learning algorithms, passing on any existing bias.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InputLayer -->

    <Class rdf:about="https://w3id.org/aio/InputLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>The input layer of a neural network is composed of artificial input neurons, and brings the initial data into the system for further processing by subsequent layers of artificial neurons. The input layer is the very beginning of the workflow for the artificial neural network.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Input Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InputLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The input layer of a neural network is composed of artificial input neurons, and brings the initial data into the system for further processing by subsequent layers of artificial neurons. The input layer is the very beginning of the workflow for the artificial neural network.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.techopedia.com/definition/33262/input-layer-neural-networks#:~:text=Explains%20Input%20Layer-,What%20Does%20Input%20Layer%20Mean%3F,for%20the%20artificial%20neural%20network.</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InputLayerLayer -->

    <Class rdf:about="https://w3id.org/aio/InputLayerLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Layer to be used as an entry point into a Network (a graph of layers).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>InputLayer Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InputLayerLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer to be used as an entry point into a Network (a graph of layers).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InputSpecLayer -->

    <Class rdf:about="https://w3id.org/aio/InputSpecLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Specifies the rank, dtype and shape of every input to a layer. Layers can expose (if appropriate) an input_spec attribute: an instance of InputSpec, or a nested structure of InputSpec instances (one per input tensor). These objects enable the layer to run input compatibility checks for input structure, input rank, input shape, and input dtype. A None entry in a shape is compatible with any dimension, a None shape is compatible with any shape.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>InputSpec Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InputSpecLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Specifies the rank, dtype and shape of every input to a layer. Layers can expose (if appropriate) an input_spec attribute: an instance of InputSpec, or a nested structure of InputSpec instances (one per input tensor). These objects enable the layer to run input compatibility checks for input structure, input rank, input shape, and input dtype. A None entry in a shape is compatible with any dimension, a None shape is compatible with any shape.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputSpec</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InstanceNorm1dLayer -->

    <Class rdf:about="https://w3id.org/aio/InstanceNorm1dLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Applies Instance Normalization over a 2D (unbatched) or 3D (batched) input as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>InstanceNorm1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>InstanceNorm1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>InstanceNorm1d Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InstanceNorm1dLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Instance Normalization over a 2D (unbatched) or 3D (batched) input as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InstanceNorm2d -->

    <Class rdf:about="https://w3id.org/aio/InstanceNorm2d">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>InstanceNorm2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>InstanceNorm2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>InstanceNorm2d</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InstanceNorm2d"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InstanceNorm3dLayer -->

    <Class rdf:about="https://w3id.org/aio/InstanceNorm3dLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>InstanceNorm3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>InstanceNorm3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>InstanceNorm3d Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InstanceNorm3dLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InstitutionalBias -->

    <Class rdf:about="https://w3id.org/aio/InstitutionalBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>Bias exhibited at the level of entire institutions, where practices or norms result in the favoring or disadvantaging of certain social groups, such as institutional racism or sexism.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Institutional Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InstitutionalBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias exhibited at the level of entire institutions, where practices or norms result in the favoring or disadvantaging of certain social groups, such as institutional racism or sexism.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Instruction-TunedLLM -->

    <Class rdf:about="https://w3id.org/aio/Instruction-TunedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An instruction-tuned LLM is fine-tuned to follow natural language instructions accurately and safely, learning to map from instructions to desired model behavior in a more controlled and principled way.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Instruction-Tuned Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>constitutional AI</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>natural language instructions</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Instruction-Tuned LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Instruction-TunedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An instruction-tuned LLM is fine-tuned to follow natural language instructions accurately and safely, learning to map from instructions to desired model behavior in a more controlled and principled way.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/IntegerLookupLayer -->

    <Class rdf:about="https://w3id.org/aio/IntegerLookupLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which maps integer features to contiguous ranges.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>IntegerLookup Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/IntegerLookupLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which maps integer features to contiguous ranges.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/InterpretationBias -->

    <Class rdf:about="https://w3id.org/aio/InterpretationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>A form of information processing bias where users interpret algorithmic outputs according to their internalized biases and views.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Interpretation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/InterpretationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A form of information processing bias where users interpret algorithmic outputs according to their internalized biases and views.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/K-nearestNeighborAlgorithm -->

    <Class rdf:about="https://w3id.org/aio/K-nearestNeighborAlgorithm">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>An algorithm that groups objects by a plurality vote of its neighbors, assigning each object to the class most common among its k nearest neighbors.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>K-NN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>KNN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>K-nearest Neighbor Algorithm</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/K-nearestNeighborAlgorithm"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An algorithm that groups objects by a plurality vote of its neighbors, assigning each object to the class most common among its k nearest neighbors.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/K-nearestNeighborClassificationAlgorithm -->

    <Class rdf:about="https://w3id.org/aio/K-nearestNeighborClassificationAlgorithm">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Classification"/>
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Clustering"/>
        <obo:IAO_0000115>An algorithm that classifies objects by a plurality vote of its neighbors, assigning each object to the class most common among its k nearest neighbors.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>K-NN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>KNN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>K-nearest Neighbor Classification Algorithm</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/K-nearestNeighborClassificationAlgorithm"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An algorithm that classifies objects by a plurality vote of its neighbors, assigning each object to the class most common among its k nearest neighbors.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/K-nearestNeighborRegressionAlgorithm -->

    <Class rdf:about="https://w3id.org/aio/K-nearestNeighborRegressionAlgorithm">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>An algorithm that assigns the average of the values of k nearest neighbors to objects.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>K-NN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>KNN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>K-nearest Neighbor Regression Algorithm</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/K-nearestNeighborRegressionAlgorithm"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An algorithm that assigns the average of the values of k nearest neighbors to objects.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Knowledge-GroundedLLM -->

    <Class rdf:about="https://w3id.org/aio/Knowledge-GroundedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A knowledge-grounded LLM incorporates external knowledge sources or knowledge bases into the model architecture, enabling it to generate more factually accurate and knowledge-aware text.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Knowledge-Grounded Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>factual grounding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>knowledge integration</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Knowledge-Grounded LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Knowledge-GroundedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A knowledge-grounded LLM incorporates external knowledge sources or knowledge bases into the model architecture, enabling it to generate more factually accurate and knowledge-aware text.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/KnowledgeTransfer -->

    <Class rdf:about="https://w3id.org/aio/KnowledgeTransfer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/TrainingStrategies"/>
        <obo:IAO_0000115>The process by which knowledge is passed from one entity, such as a person, organization, or system, to another, facilitating learning and adaptation in the receiving entity through various methods such as teaching, training, or data exchange.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Inductive Transfer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Skill Acquisition</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Adaptation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Pretrained models</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Knowledge Transfer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/KnowledgeTransfer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process by which knowledge is passed from one entity, such as a person, organization, or system, to another, facilitating learning and adaptation in the receiving entity through various methods such as teaching, training, or data exchange.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.1016/j.knosys.2015.01.010|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/KohonenNetwork -->

    <Class rdf:about="https://w3id.org/aio/KohonenNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>A self-organizing map (SOM) or Kohonen network is an unsupervised machine learning technique producing a low-dimensional representation of high-dimensional data, preserving topological structure.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>KN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>SOFM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>SOM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Self-Organizing Feature Map</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Self-Organizing Map</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden</rdfs:comment>
        <rdfs:label>Kohonen Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/KohonenNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A self-organizing map (SOM) or Kohonen network is an unsupervised machine learning technique producing a low-dimensional representation of high-dimensional data, preserving topological structure.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Self-organizing_map|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LPPool1DLayer -->

    <Class rdf:about="https://w3id.org/aio/LPPool1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 1D power-average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LPPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LPPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LPPool1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LPPool1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 1D power-average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LPPool2DLayer -->

    <Class rdf:about="https://w3id.org/aio/LPPool2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Applies a 2D power-average pooling over an input signal composed of several input planes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LPPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LPPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LPPool2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LPPool2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies a 2D power-average pooling over an input signal composed of several input planes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LSTMCellLayer -->

    <Class rdf:about="https://w3id.org/aio/LSTMCellLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Cell class for the LSTM layer.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LSTMCell Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LSTMCellLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Cell class for the LSTM layer.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LSTMLayer -->

    <Class rdf:about="https://w3id.org/aio/LSTMLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>Long Short-Term Memory layer - Hochreiter 1997. Based on available runtime hardware and constraints, this layer will choose different implementations (cuDNN-based or pure-TensorFlow) to maximize the performance. If a GPU is available and all the arguments to the layer meet the requirement of the cuDNN kernel (see below for details), the layer will use a fast cuDNN implementation. The requirements to use the cuDNN implementation are: 1. activation == tanh, 2. recurrent_activation == sigmoid, 3. recurrent_dropout == 0, 4. unroll is False, 5. use_bias is True, 6. Inputs, if use masking, are strictly right-padded, 7. Eager execution is enabled in the outermost context.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LSTM Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LSTMLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Long Short-Term Memory layer - Hochreiter 1997. Based on available runtime hardware and constraints, this layer will choose different implementations (cuDNN-based or pure-TensorFlow) to maximize the performance. If a GPU is available and all the arguments to the layer meet the requirement of the cuDNN kernel (see below for details), the layer will use a fast cuDNN implementation. The requirements to use the cuDNN implementation are: 1. activation == tanh, 2. recurrent_activation == sigmoid, 3. recurrent_dropout == 0, 4. unroll is False, 5. use_bias is True, 6. Inputs, if use masking, are strictly right-padded, 7. Eager execution is enabled in the outermost context.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LambdaLayer -->

    <Class rdf:about="https://w3id.org/aio/LambdaLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Wraps arbitrary expressions as a Layer object.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Lambda Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LambdaLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Wraps arbitrary expressions as a Layer object.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Lambda</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LanguageInterfaceLLM -->

    <Class rdf:about="https://w3id.org/aio/LanguageInterfaceLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A language interface LLM supports interactive semantic parsing, enabling users to provide feedback and corrections to dynamically refine and update the language model.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Language Interface LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Interactive learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Language Interface LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LanguageInterfaceLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A language interface LLM supports interactive semantic parsing, enabling users to provide feedback and corrections to dynamically refine and update the language model.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LanguageModel -->

    <Class rdf:about="https://w3id.org/aio/LanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>A language model is a probabilistic model designed to predict the next word in a sequence or assign probabilities to sequences of words in natural language.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A language model is a probabilistic model designed to predict the next word in a sequence or assign probabilities to sequences of words in natural language.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Language_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LargeLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/LargeLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Large Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabeled text using self-supervised learning or semi-supervised learning.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Large_language_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LassoRegression -->

    <Class rdf:about="https://w3id.org/aio/LassoRegression">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A regression analysis method that performs both variable selection and regularization to enhance prediction accuracy and interpretability.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Lasso Regression</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LassoRegression"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A regression analysis method that performs both variable selection and regularization to enhance prediction accuracy and interpretability.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Lasso_(statistics)|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Layer -->

    <Class rdf:about="https://w3id.org/aio/Layer">
        <obo:IAO_0000115>A structure or network topology in a deep learning model that takes information from previous layers and passes it to the next layer.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ClassSubset"/>
        <rdfs:label>Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Layer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A structure or network topology in a deep learning model that takes information from previous layers and passes it to the next layer.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Layer_(deep_learning)|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LayerLayer -->

    <Class rdf:about="https://w3id.org/aio/LayerLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>This is the class from which all layers inherit. A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. It involves computation, defined in the call() method, and a state (weight variables). State can be created in various places, at the convenience of the subclass implementer: in __init__(); in the optional build() method, which is invoked by the first __call__() to the layer, and supplies the shape(s) of the input(s), which may not have been known at initialization time; in the first invocation of call(), with some caveats discussed below. Users will just instantiate a layer and then treat it as a callable.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Layer Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LayerLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>This is the class from which all layers inherit. A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. It involves computation, defined in the call() method, and a state (weight variables). State can be created in various places, at the convenience of the subclass implementer: in __init__(); in the optional build() method, which is invoked by the first __call__() to the layer, and supplies the shape(s) of the input(s), which may not have been known at initialization time; in the first invocation of call(), with some caveats discussed below. Users will just instantiate a layer and then treat it as a callable.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LayerNormLayer -->

    <Class rdf:about="https://w3id.org/aio/LayerNormLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LayerNorm</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LayerNorm Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LayerNormLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LayerNormalizationLayer -->

    <Class rdf:about="https://w3id.org/aio/LayerNormalizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Layer normalization layer (Ba et al., 2016). Normalize the activations of the previous layer for each given example in a batch independently, rather than across a batch like Batch Normalization. i.e. applies a transformation that maintains the mean activation within each example close to 0 and the activation standard deviation close to 1. Given a tensor inputs, moments are calculated and normalization is performed across the axes specified in axis.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LayerNormalization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LayerNormalizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer normalization layer (Ba et al., 2016). Normalize the activations of the previous layer for each given example in a batch independently, rather than across a batch like Batch Normalization. i.e. applies a transformation that maintains the mean activation within each example close to 0 and the activation standard deviation close to 1. Given a tensor inputs, moments are calculated and normalization is performed across the axes specified in axis.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LazyBatchNorm1DLayer -->

    <Class rdf:about="https://w3id.org/aio/LazyBatchNorm1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>A torch.nn.BatchNorm1d module with lazy initialization of the num_features argument of the BatchNorm1d that is inferred from the input.size(1).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LazyBatchNorm1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LazyBatchNorm1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LazyBatchNorm1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LazyBatchNorm1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A torch.nn.BatchNorm1d module with lazy initialization of the num_features argument of the BatchNorm1d that is inferred from the input.size(1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LazyBatchNorm2DLayer -->

    <Class rdf:about="https://w3id.org/aio/LazyBatchNorm2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>A torch.nn.BatchNorm2d module with lazy initialization of the num_features argument of the BatchNorm2d that is inferred from the input.size(1).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LazyBatchNorm2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LazyBatchNorm2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LazyBatchNorm2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LazyBatchNorm2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A torch.nn.BatchNorm2d module with lazy initialization of the num_features argument of the BatchNorm2d that is inferred from the input.size(1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LazyBatchNorm3DLayer -->

    <Class rdf:about="https://w3id.org/aio/LazyBatchNorm3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>A torch.nn.BatchNorm3d module with lazy initialization of the num_features argument of the BatchNorm3d that is inferred from the input.size(1).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LazyBatchNorm3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LazyBatchNorm3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LazyBatchNorm3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LazyBatchNorm3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A torch.nn.BatchNorm3d module with lazy initialization of the num_features argument of the BatchNorm3d that is inferred from the input.size(1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LazyInstanceNorm1dLayer -->

    <Class rdf:about="https://w3id.org/aio/LazyInstanceNorm1dLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>A torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument of the InstanceNorm1d that is inferred from the input.size(1).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LazyInstanceNorm1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LazyInstanceNorm1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LazyInstanceNorm1d Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LazyInstanceNorm1dLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument of the InstanceNorm1d that is inferred from the input.size(1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LazyInstanceNorm2dLayer -->

    <Class rdf:about="https://w3id.org/aio/LazyInstanceNorm2dLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>A torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument of the InstanceNorm2d that is inferred from the input.size(1).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LazyInstanceNorm2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LazyInstanceNorm2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LazyInstanceNorm2d Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LazyInstanceNorm2dLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument of the InstanceNorm2d that is inferred from the input.size(1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LazyInstanceNorm3dLayer -->

    <Class rdf:about="https://w3id.org/aio/LazyInstanceNorm3dLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>A torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument of the InstanceNorm3d that is inferred from the input.size(1).</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LazyInstanceNorm3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>LazyInstanceNorm3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LazyInstanceNorm3d Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LazyInstanceNorm3dLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument of the InstanceNorm3d that is inferred from the input.size(1).</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LeakyReLULayer -->

    <Class rdf:about="https://w3id.org/aio/LeakyReLULayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <obo:IAO_0000115>Leaky version of a Rectified Linear Unit.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LeakyReLU Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LeakyReLULayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Leaky version of a Rectified Linear Unit.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Least-squaresAnalysis -->

    <Class rdf:about="https://w3id.org/aio/Least-squaresAnalysis">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A standard approach in regression analysis to approximate the solution of overdetermined systems by minimizing the sum of the squares of the residuals.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Least-squares Analysis</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Least-squaresAnalysis"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A standard approach in regression analysis to approximate the solution of overdetermined systems by minimizing the sum of the squares of the residuals.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Least_squares|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LifelongLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/LifelongLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A lifelong learning LLM continually acquires new knowledge over time without forgetting previously learned information, maintaining a balance between plasticity and stability.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Continual Learning LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Forever Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Lifelong Learning LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Catastrophic forgetting</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Plasticity-Stability balance</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Lifelong Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LifelongLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A lifelong learning LLM continually acquires new knowledge over time without forgetting previously learned information, maintaining a balance between plasticity and stability.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LinearFunction -->

    <Class rdf:about="https://w3id.org/aio/LinearFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>A linear function has the form f(x) = a + bx.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Linear Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LinearFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A linear function has the form f(x) = a + bx.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LinearRegression -->

    <Class rdf:about="https://w3id.org/aio/LinearRegression">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A linear approach for modeling the relationship between a scalar response and one or more explanatory variables.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Linear Regression</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LinearRegression"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A linear approach for modeling the relationship between a scalar response and one or more explanatory variables.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Linear_regression|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LinkingBias -->

    <Class rdf:about="https://w3id.org/aio/LinkingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <obo:IAO_0000115>Bias arising when network attributes obtained from user connections, activities, or interactions misrepresent true user behavior.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Linking Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LinkingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when network attributes obtained from user connections, activities, or interactions misrepresent true user behavior.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LiquidStateMachineNetwork -->

    <Class rdf:about="https://w3id.org/aio/LiquidStateMachineNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>A liquid state machine (LSM) is a type of reservoir computer using a spiking neural network, with recurrently connected nodes turning time-varying input into spatio-temporal activation patterns.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LSM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Spiking Hidden, Output</rdfs:comment>
        <rdfs:label>Liquid State Machine Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LiquidStateMachineNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A liquid state machine (LSM) is a type of reservoir computer using a spiking neural network, with recurrently connected nodes turning time-varying input into spatio-temporal activation patterns.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Liquid_state_machine|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LocalResponseNormLayer -->

    <Class rdf:about="https://w3id.org/aio/LocalResponseNormLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <obo:IAO_0000115>Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LocalResponseNorm</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LocalResponseNorm Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LocalResponseNormLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Locally-connectedLayer -->

    <Class rdf:about="https://w3id.org/aio/Locally-connectedLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>The LocallyConnected1D layer works similarly to the Convolution1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Locally-connected Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Locally-connectedLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The LocallyConnected1D layer works similarly to the Convolution1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://faroit.com/keras-docs/1.2.2/layers/local/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LocallyConnected1DLayer -->

    <Class rdf:about="https://w3id.org/aio/LocallyConnected1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Locally-connectedLayer"/>
        <obo:IAO_0000115>Locally-connected layer for 1D inputs. The LocallyConnected1D layer works similarly to the Conv1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LocallyConnected1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LocallyConnected1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Locally-connected layer for 1D inputs. The LocallyConnected1D layer works similarly to the Conv1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LocallyConnected1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LocallyConnected2DLayer -->

    <Class rdf:about="https://w3id.org/aio/LocallyConnected2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Locally-connectedLayer"/>
        <obo:IAO_0000115>Locally-connected layer for 2D inputs. The LocallyConnected2D layer works similarly to the Conv2D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>LocallyConnected2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LocallyConnected2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Locally-connected layer for 2D inputs. The LocallyConnected2D layer works similarly to the Conv2D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/LocallyConnected2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LogisticRegression -->

    <Class rdf:about="https://w3id.org/aio/LogisticRegression">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A statistical model that estimates the probability of an event occurring by modeling the log-odds of the event as a linear combination of one or more independent variables.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Logistic Regression</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LogisticRegression"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A statistical model that estimates the probability of an event occurring by modeling the log-odds of the event as a linear combination of one or more independent variables.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Logistic_regression|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LongShortTermMemory -->

    <Class rdf:about="https://w3id.org/aio/LongShortTermMemory">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentNeuralNetwork"/>
        <obo:IAO_0000115>Long short-term memory (LSTM) networks are artificial recurrent neural networks with feedback connections, processing entire sequences of data for tasks like handwriting and speech recognition.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>LSTM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Memory Cell, Output</rdfs:comment>
        <rdfs:label>Long Short Term Memory</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LongShortTermMemory"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Long short-term memory (LSTM) networks are artificial recurrent neural networks with feedback connections, processing entire sequences of data for tasks like handwriting and speech recognition.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Long_short-term_memory|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/LossOfSituationalAwarenessBias -->

    <Class rdf:about="https://w3id.org/aio/LossOfSituationalAwarenessBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>When automation leads to humans being unaware of their situation, making them unprepared to assume control in cooperative systems.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Loss Of Situational Awareness Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/LossOfSituationalAwarenessBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>When automation leads to humans being unaware of their situation, making them unprepared to assume control in cooperative systems.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Low-ResourceLLM -->

    <Class rdf:about="https://w3id.org/aio/Low-ResourceLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A low-resource LLM is optimized for performance in scenarios with limited data, computational resources, or for languages with sparse datasets.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Low-Resource Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>low-resource languages</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>resource-efficient</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Low-Resource LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Low-ResourceLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A low-resource LLM is optimized for performance in scenarios with limited data, computational resources, or for languages with sparse datasets.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MachineLearning -->

    <Class rdf:about="https://w3id.org/aio/MachineLearning">
        <obo:IAO_0000115>A field of inquiry devoted to understanding and building methods that learn from data to improve performance on a set of tasks.</obo:IAO_0000115>
        <rdfs:label>Machine Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A field of inquiry devoted to understanding and building methods that learn from data to improve performance on a set of tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ManifoldLearning -->

    <Class rdf:about="https://w3id.org/aio/ManifoldLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DimensionalityReduction"/>
        <obo:IAO_0000115>Methods based on the assumption that observed data lie on a low-dimensional manifold embedded in a higher-dimensional space.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Manifold Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ManifoldLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods based on the assumption that observed data lie on a low-dimensional manifold embedded in a higher-dimensional space.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2011.01307|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MarkovChain -->

    <Class rdf:about="https://w3id.org/aio/MarkovChain">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>A Markov chain is a stochastic model describing a sequence of possible events where the probability of each event depends only on the previous event&apos;s state.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MC</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MP</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Markov Process</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:comment>Layers: Probalistic Hidden</rdfs:comment>
        <rdfs:label>Markov Chain</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MarkovChain"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A Markov chain is a stochastic model describing a sequence of possible events where the probability of each event depends only on the previous event&apos;s state.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Markov_chain|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaskedLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/MaskedLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A masked language model is trained to predict randomly masked tokens in a sequence, based on the remaining unmasked tokens. This allows it to build deep bidirectional representations that can be effectively transferred to various NLP tasks via fine-tuning.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Masked Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>bidirectional encoder</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>denoising autoencoder</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Masked Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaskedLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A masked language model is trained to predict randomly masked tokens in a sequence, based on the remaining unmasked tokens. This allows it to build deep bidirectional representations that can be effectively transferred to various NLP tasks via fine-tuning.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaskingLayer -->

    <Class rdf:about="https://w3id.org/aio/MaskingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Masks a sequence by using a mask value to skip timesteps. For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to mask_value, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking). If any downstream layer does not support masking yet receives such an input mask, an exception will be raised.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Masking Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaskingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Masks a sequence by using a mask value to skip timesteps. For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to mask_value, then the timestep will be masked (skipped) in all downstream layers (as long as they support masking). If any downstream layer does not support masking yet receives such an input mask, an exception will be raised.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaxPooling1DLayer -->

    <Class rdf:about="https://w3id.org/aio/MaxPooling1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides. The resulting output, when using the &quot;valid&quot; padding option, has a shape of: output_shape = (input_shape - pool_size + 1) / strides) The resulting output shape when using the &quot;same&quot; padding option is: output_shape = input_shape / strides.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MaxPool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPooling1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPooling1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MaxPooling1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaxPooling1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides. The resulting output, when using the &quot;valid&quot; padding option, has a shape of: output_shape = (input_shape - pool_size + 1) / strides) The resulting output shape when using the &quot;same&quot; padding option is: output_shape = input_shape / strides.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaxPooling2DLayer -->

    <Class rdf:about="https://w3id.org/aio/MaxPooling2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Max pooling operation for 2D spatial data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MaxPool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPooling2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPooling2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MaxPooling2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaxPooling2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Max pooling operation for 2D spatial data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaxPooling3DLayer -->

    <Class rdf:about="https://w3id.org/aio/MaxPooling3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Max pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MaxPool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPooling3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxPooling3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MaxPooling3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaxPooling3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Max pooling operation for 3D data (spatial or spatio-temporal). Downsamples the input along its spatial dimensions (depth, height, and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaxUnpool1DLayer -->

    <Class rdf:about="https://w3id.org/aio/MaxUnpool1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Computes a partial inverse of MaxPool1d.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MaxUnpool1D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxUnpool1d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MaxUnpool1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaxUnpool1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Computes a partial inverse of MaxPool1d.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaxUnpool2DLayer -->

    <Class rdf:about="https://w3id.org/aio/MaxUnpool2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Computes a partial inverse of MaxPool2d.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MaxUnpool2D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxUnpool2d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MaxUnpool2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaxUnpool2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Computes a partial inverse of MaxPool2d.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaxUnpool3DLayer -->

    <Class rdf:about="https://w3id.org/aio/MaxUnpool3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <obo:IAO_0000115>Computes a partial inverse of MaxPool3d.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MaxUnpool3D</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MaxUnpool3d</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MaxUnpool3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaxUnpool3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Computes a partial inverse of MaxPool3d.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#pooling-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MaximumLayer -->

    <Class rdf:about="https://w3id.org/aio/MaximumLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that computes the maximum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Maximum Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MaximumLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that computes the maximum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Maximum</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MeasurementBias -->

    <Class rdf:about="https://w3id.org/aio/MeasurementBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias arising when features and labels are proxies for desired quantities, potentially leading to differential performance.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Measurement Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MeasurementBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when features and labels are proxies for desired quantities, potentially leading to differential performance.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Memory-AugmentedLLM -->

    <Class rdf:about="https://w3id.org/aio/Memory-AugmentedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A memory-augmented LLM incorporates external writable and readable memory components, allowing it to store and retrieve information over long contexts.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Memory-Augmented Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>external memory</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Memory-Augmented LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Memory-AugmentedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A memory-augmented LLM incorporates external writable and readable memory components, allowing it to store and retrieve information over long contexts.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2306.07174|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MergingLayer -->

    <Class rdf:about="https://w3id.org/aio/MergingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer used to merge a list of inputs.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Merging Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer used to merge a list of inputs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tutorialspoint.com/keras/keras_merge_layer.htm</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Meta-Learning -->

    <Class rdf:about="https://w3id.org/aio/Meta-Learning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods for creating automatic learning algorithms that learn from metadata about machine learning experiments.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Meta-Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Meta-Learning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods for creating automatic learning algorithms that learn from metadata about machine learning experiments.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Meta-LearningLLM -->

    <Class rdf:about="https://w3id.org/aio/Meta-LearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A meta-learning LLM is trained in a way that allows it to quickly adapt to new tasks or datasets through only a few examples or fine-tuning steps, leveraging meta-learned priors about how to efficiently learn.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Meta-Learning Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>few-shot adaptation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>learning to learn</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Meta-Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Meta-LearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A meta-learning LLM is trained in a way that allows it to quickly adapt to new tasks or datasets through only a few examples or fine-tuning steps, leveraging meta-learned priors about how to efficiently learn.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MetricLearning -->

    <Class rdf:about="https://w3id.org/aio/MetricLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Learning a representation function that maps objects into an embedded space.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Distance Metric Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Metric Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MetricLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Learning a representation function that maps objects into an embedded space.</annotatedTarget>
        <oboInOwl:hasDbXref>https://paperswithcode.com/task/metric-learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MinimumLayer -->

    <Class rdf:about="https://w3id.org/aio/MinimumLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that computes the minimum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Minimum Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MinimumLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that computes the minimum (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Minimum</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Mixture-of-ExpertsLLM -->

    <Class rdf:about="https://w3id.org/aio/Mixture-of-ExpertsLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A Mixture-of-Experts LLM dynamically selects and combines outputs from multiple expert submodels, allowing for efficient scaling by conditionally activating only a subset of model components for each input.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Mixture-of-Experts Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>MoE Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>conditional computation</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>model parallelism</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Mixture-of-Experts LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Mixture-of-ExpertsLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A Mixture-of-Experts LLM dynamically selects and combines outputs from multiple expert submodels, allowing for efficient scaling by conditionally activating only a subset of model components for each input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://proceedings.mlr.press/v162/du22c.html|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ModeConfusionBias -->

    <Class rdf:about="https://w3id.org/aio/ModeConfusionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>When modal interfaces confuse human operators, causing actions appropriate for a different mode but incorrect for the current situation.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Mode Confusion Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ModeConfusionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>When modal interfaces confuse human operators, causing actions appropriate for a different mode but incorrect for the current situation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Model -->

    <Class rdf:about="https://w3id.org/aio/Model">
        <obo:IAO_0000115>A model is an abstract representation of a complex system, generally assembled as a set of logical, mathematical, or conceptual properties to simulate or understand the system&apos;s behavior.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Model"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A model is an abstract representation of a complex system, generally assembled as a set of logical, mathematical, or conceptual properties to simulate or understand the system&apos;s behavior.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Mathematical_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ModelEfficiency -->

    <Class rdf:about="https://w3id.org/aio/ModelEfficiency">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Preprocessing"/>
        <obo:IAO_0000115>Techniques aimed at making models more efficient, such as knowledge distillation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Computational Efficiency</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Model Optimization</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Model Efficiency</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ModelEfficiency"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Techniques aimed at making models more efficient, such as knowledge distillation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.1145/3578938|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ModelSelectionBias -->

    <Class rdf:about="https://w3id.org/aio/ModelSelectionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProcessingBias"/>
        <obo:IAO_0000115>Bias introduced when using data to select a single &quot;best&quot; model from many, or when an explanatory variable has a weak relationship with the response variable.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Model Selection Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ModelSelectionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias introduced when using data to select a single &quot;best&quot; model from many, or when an explanatory variable has a weak relationship with the response variable.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ModularLLM -->

    <Class rdf:about="https://w3id.org/aio/ModularLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ModularLanguageModel"/>
        <obo:IAO_0000115>A modular LLM consists of multiple specialized components or skills that can be dynamically composed and recombined to solve complex tasks, mimicking the modular structure of human cognition.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Modular Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>component skills</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>skill composition</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Modular LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ModularLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A modular LLM consists of multiple specialized components or skills that can be dynamically composed and recombined to solve complex tasks, mimicking the modular structure of human cognition.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2302.11529v2|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ModularLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/ModularLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A modular language model consists of multiple specialized components or skills that can be dynamically composed and recombined to solve complex tasks, mimicking the modular structure of human cognition.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Modular LM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Modular Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ModularLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A modular language model consists of multiple specialized components or skills that can be dynamically composed and recombined to solve complex tasks, mimicking the modular structure of human cognition.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2302.11529v2|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Multi-TaskLLM -->

    <Class rdf:about="https://w3id.org/aio/Multi-TaskLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A multi-task LLM is trained jointly on multiple language tasks simultaneously, learning shared representations that transfer across tasks.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multi-Task Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>transfer learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multi-Task LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Multi-TaskLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multi-task LLM is trained jointly on multiple language tasks simultaneously, learning shared representations that transfer across tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultiHeadAttentionLayer -->

    <Class rdf:about="https://w3id.org/aio/MultiHeadAttentionLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AttentionLayer"/>
        <obo:IAO_0000115>MultiHeadAttention layer. This is an implementation of multi-headed attention as described in the paper &quot;Attention is all you Need&quot; (Vaswani et al., 2017). If query, key, value are the same, then this is self-attention. Each timestep in query attends to the corresponding sequence in key, and returns a fixed-width vector.This layer first projects query, key and value. These are (effectively) a list of tensors of length num_attention_heads, where the corresponding shapes are (batch_size, &lt;query dimensions&gt;, key_dim), (batch_size, &lt;key/value dimensions&gt;, key_dim), (batch_size, &lt;key/value dimensions&gt;, value_dim).Then, the query and key tensors are dot-producted and scaled. These are softmaxed to obtain attention probabilities. The value tensors are then interpolated by these probabilities, then concatenated back to a single tensor. Finally, the result tensor with the last dimension as value_dim can take an linear projection and return. When using MultiHeadAttention inside a custom Layer, the custom Layer must implement build() and call MultiHeadAttention&apos;s _build_from_signature(). This enables weights to be restored correctly when the model is loaded.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>MultiHeadAttention Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultiHeadAttentionLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>MultiHeadAttention layer. This is an implementation of multi-headed attention as described in the paper &quot;Attention is all you Need&quot; (Vaswani et al., 2017). If query, key, value are the same, then this is self-attention. Each timestep in query attends to the corresponding sequence in key, and returns a fixed-width vector.This layer first projects query, key and value. These are (effectively) a list of tensors of length num_attention_heads, where the corresponding shapes are (batch_size, &lt;query dimensions&gt;, key_dim), (batch_size, &lt;key/value dimensions&gt;, key_dim), (batch_size, &lt;key/value dimensions&gt;, value_dim).Then, the query and key tensors are dot-producted and scaled. These are softmaxed to obtain attention probabilities. The value tensors are then interpolated by these probabilities, then concatenated back to a single tensor. Finally, the result tensor with the last dimension as value_dim can take an linear projection and return. When using MultiHeadAttention inside a custom Layer, the custom Layer must implement build() and call MultiHeadAttention&apos;s _build_from_signature(). This enables weights to be restored correctly when the model is loaded.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MulticlassClassification -->

    <Class rdf:about="https://w3id.org/aio/MulticlassClassification">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Classification"/>
        <obo:IAO_0000115>Methods that classify instances into one of three or more classes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multinomial Classification</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Multiclass Classification</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MulticlassClassification"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that classify instances into one of three or more classes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Multiclass_classification|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultidimensionalScaling -->

    <Class rdf:about="https://w3id.org/aio/MultidimensionalScaling">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DimensionalityReduction"/>
        <obo:IAO_0000115>A method that translates information about the pairwise distances among a set of objects or individuals into a configuration of points mapped into an abstract Cartesian space.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>MDS</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Multidimensional Scaling</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultidimensionalScaling"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A method that translates information about the pairwise distances among a set of objects or individuals into a configuration of points mapped into an abstract Cartesian space.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Multidimensional_scaling|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultilingualLLM -->

    <Class rdf:about="https://w3id.org/aio/MultilingualLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A multilingual LLM is trained on text from multiple languages, learning shared representations that enable zero-shot or few-shot transfer to new languages.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multilingual Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>cross-lingual transfer</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multilingual LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultilingualLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multilingual LLM is trained on text from multiple languages, learning shared representations that enable zero-shot or few-shot transfer to new languages.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalDeepLearning -->

    <Class rdf:about="https://w3id.org/aio/MultimodalDeepLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Creating models that process and link information using various modalities.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Multimodal Deep Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalDeepLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Creating models that process and link information using various modalities.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2105.11087|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalFusionLLM -->

    <Class rdf:about="https://w3id.org/aio/MultimodalFusionLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A multimodal fusion LLM learns joint representations across different modalities like text, vision, and audio in an end-to-end fashion for better cross-modal understanding and generation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multimodal Fusion LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>cross-modal grounding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multimodal Fusion LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalFusionLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multimodal fusion LLM learns joint representations across different modalities like text, vision, and audio in an end-to-end fashion for better cross-modal understanding and generation.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalLLM -->

    <Class rdf:about="https://w3id.org/aio/MultimodalLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MultimodalLanguageModel"/>
        <obo:IAO_0000115>A multimodal LLM learns joint representations across different modalities like text, vision, and audio in an end-to-end fashion for better cross-modal understanding and generation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multimodal Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>cross-modal grounding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multimodal LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multimodal LLM learns joint representations across different modalities like text, vision, and audio in an end-to-end fashion for better cross-modal understanding and generation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2303.17580|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/MultimodalLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A multimodal language model learns joint representations across different modalities like text, vision, and audio in an end-to-end fashion for better cross-modal understanding and generation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Mulimodal LM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multimodal Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multimodal language model learns joint representations across different modalities like text, vision, and audio in an end-to-end fashion for better cross-modal understanding and generation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2205.12630|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalLearning -->

    <Class rdf:about="https://w3id.org/aio/MultimodalLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>A type of deep learning that uses multiple modalities of data, such as text, audio, and images, to improve learning outcomes.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Multimodal Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A type of deep learning that uses multiple modalities of data, such as text, audio, and images, to improve learning outcomes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalPrompt-basedLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/MultimodalPrompt-basedLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MultimodalLanguageModel"/>
        <obo:IAO_0000115>A multimodal prompt-based language model processes prompts that include multiple modalities, such as both text and images, to generate relevant responses.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multimodal Prompt-based Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multimodal Prompt-based Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalPrompt-basedLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multimodal prompt-based language model processes prompts that include multiple modalities, such as both text and images, to generate relevant responses.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/2210.03094|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultimodalTransformer -->

    <Class rdf:about="https://w3id.org/aio/MultimodalTransformer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/TransformerNetwork"/>
        <obo:IAO_0000115>A multimodal transformer processes and relates information from different modalities, such as text, images, and audio. It uses a shared embedding space and attention mechanism to learn joint representations across modalities.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Multimodal Transformer</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>unified encoder</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>vision-language model</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Multimodal Transformer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultimodalTransformer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A multimodal transformer processes and relates information from different modalities, such as text, images, and audio. It uses a shared embedding space and attention mechanism to learn joint representations across modalities.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/MultiplyLayer -->

    <Class rdf:about="https://w3id.org/aio/MultiplyLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that multiplies (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Multiply Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/MultiplyLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that multiplies (element-wise) a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Multiply</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/NaturalLanguageProcessing -->

    <Class rdf:about="https://w3id.org/aio/NaturalLanguageProcessing">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>A subfield of linguistics, computer science, and artificial intelligence focused on the interactions between computers and human language, including programming computers to process and analyze large amounts of natural language data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>NLP</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Natural Language Processing</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/NaturalLanguageProcessing"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A subfield of linguistics, computer science, and artificial intelligence focused on the interactions between computers and human language, including programming computers to process and analyze large amounts of natural language data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Natural_language_processing|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Network -->

    <Class rdf:about="https://w3id.org/aio/Network">
        <obo:IAO_0000115>A system of interconnected nodes or entities for communication, computation, or data exchange.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ClassSubset"/>
        <rdfs:label>Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Network"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A system of interconnected nodes or entities for communication, computation, or data exchange.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/NeuralTuringMachineNetwork -->

    <Class rdf:about="https://w3id.org/aio/NeuralTuringMachineNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepFeedForward"/>
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LongShortTermMemory"/>
        <obo:IAO_0000115>A neural Turing machine (NTM) combines neural network pattern matching with the algorithmic power of programmable computers, using attention mechanisms to interact with external memory for tasks like copying, sorting, and associative recall.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>NTM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Spiking Hidden, Output</rdfs:comment>
        <rdfs:label>Neural Turing Machine Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/NeuralTuringMachineNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A neural Turing machine (NTM) combines neural network pattern matching with the algorithmic power of programmable computers, using attention mechanisms to interact with external memory for tasks like copying, sorting, and associative recall.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Neural_Turing_machine|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Neuro-SymbolicLLM -->

    <Class rdf:about="https://w3id.org/aio/Neuro-SymbolicLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A neuro-symbolic LLM combines neural language modeling with symbolic reasoning components, leveraging structured knowledge representations and logical inferences to improve reasoning capabilities.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Neuro-Symbolic Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>knowledge reasoning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>symbolic grounding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Neuro-Symbolic LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Neuro-SymbolicLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A neuro-symbolic LLM combines neural language modeling with symbolic reasoning components, leveraging structured knowledge representations and logical inferences to improve reasoning capabilities.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/NoiseDenseLayer -->

    <Class rdf:about="https://w3id.org/aio/NoiseDenseLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Noisy dense layer that injects random noise to the weights of dense layer. Noisy dense layers are fully connected layers whose weights and biases are augmented by factorised Gaussian noise. The factorised Gaussian noise is controlled through gradient descent by a second weights layer. A NoisyDense layer implements the operation: $$ mathrm{NoisyDense}(x) = mathrm{activation}(mathrm{dot}(x, mu + (sigma cdot epsilon)) mathrm{bias}) $$ where mu is the standard weights layer, epsilon is the factorised Gaussian noise, and delta is a second weights layer which controls epsilon.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Noise Dense Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/NoiseDenseLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Noisy dense layer that injects random noise to the weights of dense layer. Noisy dense layers are fully connected layers whose weights and biases are augmented by factorised Gaussian noise. The factorised Gaussian noise is controlled through gradient descent by a second weights layer. A NoisyDense layer implements the operation: $$ mathrm{NoisyDense}(x) = mathrm{activation}(mathrm{dot}(x, mu + (sigma cdot epsilon)) mathrm{bias}) $$ where mu is the standard weights layer, epsilon is the factorised Gaussian noise, and delta is a second weights layer which controls epsilon.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/addons/api_docs/python/tfa/layers/NoisyDense</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/NormalizationLayer -->

    <Class rdf:about="https://w3id.org/aio/NormalizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/NumericalFeaturesPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which normalizes continuous features.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Normalization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/NormalizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which normalizes continuous features.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/NumericalFeaturesPreprocessingLayer -->

    <Class rdf:about="https://w3id.org/aio/NumericalFeaturesPreprocessingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that performs numerical data preprocessing operations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Numerical Features Preprocessing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/NumericalFeaturesPreprocessingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that performs numerical data preprocessing operations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/guides/preprocessing_layers/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/One-shotLearning -->

    <Class rdf:about="https://w3id.org/aio/One-shotLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Classifying objects from one or only a few examples.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>OSL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>One-shot Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/One-shotLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Classifying objects from one or only a few examples.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/One-shot_learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/OrdinalLLM -->

    <Class rdf:about="https://w3id.org/aio/OrdinalLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An ordinal LLM is trained to model ordinal relationships and rank outputs, rather than model probability distributions over text sequences directly.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Ordinal Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>preference modeling</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>ranking</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Ordinal LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/OrdinalLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An ordinal LLM is trained to model ordinal relationships and rank outputs, rather than model probability distributions over text sequences directly.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/OutputLayer -->

    <Class rdf:about="https://w3id.org/aio/OutputLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>The output layer in an artificial neural network is the last layer of neurons that produces given outputs for the program. Though they are made much like other artificial neurons in the neural network, output layer neurons may be built or observed in a different way, given that they are the last “actor” nodes on the network.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Output Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/OutputLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The output layer in an artificial neural network is the last layer of neurons that produces given outputs for the program. Though they are made much like other artificial neurons in the neural network, output layer neurons may be built or observed in a different way, given that they are the last “actor” nodes on the network.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.techopedia.com/definition/33263/output-layer-neural-networks</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PReLULayer -->

    <Class rdf:about="https://w3id.org/aio/PReLULayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <obo:IAO_0000115>Parametric Rectified Linear Unit.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>PReLU Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PReLULayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Parametric Rectified Linear Unit.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/PReLU</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Perceptron -->

    <Class rdf:about="https://w3id.org/aio/Perceptron">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ArtificialNeuralNetwork"/>
        <obo:IAO_0000115>A perceptron is a supervised learning algorithm for binary classification, deciding if an input belongs to a class using a linear predictor function that combines weights with the feature vector.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>FFN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Feed-Forward Network</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>SLP</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Single Layer Perceptron</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Output</rdfs:comment>
        <rdfs:label>Perceptron</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Perceptron"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A perceptron is a supervised learning algorithm for binary classification, deciding if an input belongs to a class using a linear predictor function that combines weights with the feature vector.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PermuteLayer -->

    <Class rdf:about="https://w3id.org/aio/PermuteLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Permutes the dimensions of the input according to a given pattern. Useful e.g. connecting RNNs and convnets.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Permute Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PermuteLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Permutes the dimensions of the input according to a given pattern. Useful e.g. connecting RNNs and convnets.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Permute</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PersonalizedLLM -->

    <Class rdf:about="https://w3id.org/aio/PersonalizedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A personalized LLM adapts its language modeling and generation to the preferences, style, and persona of individual users or audiences.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Personalized Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>user adaptation LLM</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Personalized LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PersonalizedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A personalized LLM adapts its language modeling and generation to the preferences, style, and persona of individual users or audiences.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PoolingLayer -->

    <Class rdf:about="https://w3id.org/aio/PoolingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Pooling layers serve the dual purposes of mitigating the sensitivity of convolutional layers to location and of spatially downsampling representations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Pooling Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PoolingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Pooling layers serve the dual purposes of mitigating the sensitivity of convolutional layers to location and of spatially downsampling representations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://d2l.ai/chapter_convolutional-neural-networks/pooling.html</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PopularityBias -->

    <Class rdf:about="https://w3id.org/aio/PopularityBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Selection bias where more popular items are more exposed, under-representing less popular items.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Popularity Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PopularityBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Selection bias where more popular items are more exposed, under-representing less popular items.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PopulationBias -->

    <Class rdf:about="https://w3id.org/aio/PopulationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Systematic distortions in demographics or other user characteristics between represented users and the target population.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Population Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PopulationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Systematic distortions in demographics or other user characteristics between represented users and the target population.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Preprocessing -->

    <Class rdf:about="https://w3id.org/aio/Preprocessing">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>The series of steps applied to raw data before it is used in a machine learning model, including tasks such as normalization, scaling, encoding, and transformation, to ensure the data is in an appropriate format and quality for analysis.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Preprocessing</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Preprocessing"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The series of steps applied to raw data before it is used in a machine learning model, including tasks such as normalization, scaling, encoding, and transformation, to ensure the data is in an appropriate format and quality for analysis.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.1109/ICDE.2019.00245|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PreprocessingLayer -->

    <Class rdf:about="https://w3id.org/aio/PreprocessingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that performs data preprocessing operations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Preprocessing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PreprocessingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that performs data preprocessing operations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/guide/keras/preprocessing_layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PresentationBias -->

    <Class rdf:about="https://w3id.org/aio/PresentationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Bias arising from how information is presented on the Web, via a user interface, due to rating or ranking of output, or through users&apos; self-selected, biased interaction.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Presentation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PresentationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising from how information is presented on the Web, via a user interface, due to rating or ranking of output, or through users&apos; self-selected, biased interaction.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/PrincipalComponentAnalysis -->

    <Class rdf:about="https://w3id.org/aio/PrincipalComponentAnalysis">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DimensionalityReduction"/>
        <obo:IAO_0000115>A method for analyzing large datasets with high-dimensional features per observation, increasing data interpretability while preserving maximum information and enabling visualization of multidimensional data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>PCA</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Principal Component Analysis</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/PrincipalComponentAnalysis"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A method for analyzing large datasets with high-dimensional features per observation, increasing data interpretability while preserving maximum information and enabling visualization of multidimensional data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Principal_component_analysis|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ProbabilisticGraphicalModel -->

    <Class rdf:about="https://w3id.org/aio/ProbabilisticGraphicalModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>A probabilistic model in which a graph expresses the conditional dependence structure between random variables.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Graphical Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>PGM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Structure Probabilistic Model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Probabilistic Graphical Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ProbabilisticGraphicalModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A probabilistic model in which a graph expresses the conditional dependence structure between random variables.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Graphical_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ProbabilisticTopicModel -->

    <Class rdf:about="https://w3id.org/aio/ProbabilisticTopicModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProbabilisticGraphicalModel"/>
        <obo:IAO_0000115>Methods that use statistical techniques to analyze the words in each text to discover common themes, their connections, and their changes over time.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Probabilistic Topic Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ProbabilisticTopicModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that use statistical techniques to analyze the words in each text to discover common themes, their connections, and their changes over time.</annotatedTarget>
        <oboInOwl:hasDbXref>https://pyro.ai/examples/prodlda.html|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ProcessingBias -->

    <Class rdf:about="https://w3id.org/aio/ProcessingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ComputationalBias"/>
        <obo:IAO_0000115>Judgment modulated by affect, influenced by the level of efficacy and efficiency in information processing; often referred to as aesthetic judgment in cognitive sciences.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Validation Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Processing Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ProcessingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Judgment modulated by affect, influenced by the level of efficacy and efficiency in information processing; often referred to as aesthetic judgment in cognitive sciences.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Bias_(statistics)|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Prompt-basedFine-TuningLLM -->

    <Class rdf:about="https://w3id.org/aio/Prompt-basedFine-TuningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A prompt-tuned LLM is fine-tuned on a small number of examples or prompts, rather than full task datasets. This allows for rapid adaptation to new tasks with limited data, leveraging the model&apos;s few-shot learning capabilities.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Prompt-based Fine-Tuning Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Prompt-tuned Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>few-shot learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>in-context learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Prompt-based Fine-Tuning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Prompt-basedFine-TuningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A prompt-tuned LLM is fine-tuned on a small number of examples or prompts, rather than full task datasets. This allows for rapid adaptation to new tasks with limited data, leveraging the model&apos;s few-shot learning capabilities.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ProportionalHazardsModel -->

    <Class rdf:about="https://w3id.org/aio/ProportionalHazardsModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SurvivalAnalysis"/>
        <obo:IAO_0000115>A survival modeling method where the unique effect of a unit increase in a covariate is multiplicative with respect to the hazard rate.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Proportional Hazards Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ProportionalHazardsModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A survival modeling method where the unique effect of a unit increase in a covariate is multiplicative with respect to the hazard rate.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Proportional_hazards_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RNNLayer -->

    <Class rdf:about="https://w3id.org/aio/RNNLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>Base class for recurrent layers.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RNN Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RNNLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Base class for recurrent layers.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RadialBasisNetwork -->

    <Class rdf:about="https://w3id.org/aio/RadialBasisNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepFeedForward"/>
        <obo:IAO_0000115>Radial basis function networks use radial basis functions as activation functions, effective for pattern recognition and interpolation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>RBFN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>RBN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Radial Basis Function Network</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>Radial Basis Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RadialBasisNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Radial basis function networks use radial basis functions as activation functions, effective for pattern recognition and interpolation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Radial_basis_function_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomBrightnessLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomBrightnessLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly adjusts brightness during training. This layer will randomly increase/reduce the brightness for the input RGB images. At inference time, the output will be identical to the input. Call the layer with training=True to adjust the brightness of the input. Note that different brightness adjustment factors will be apply to each the images in the batch.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomBrightness Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomBrightnessLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly adjusts brightness during training. This layer will randomly increase/reduce the brightness for the input RGB images. At inference time, the output will be identical to the input. Call the layer with training=True to adjust the brightness of the input. Note that different brightness adjustment factors will be apply to each the images in the batch.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomContrastLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomContrastLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly adjusts contrast during training. This layer will randomly adjust the contrast of an image or images by a random factor. Contrast is adjusted independently for each channel of each image during training. For each channel, this layer computes the mean of the image pixels in the channel and then adjusts each component x of each pixel to (x - mean) * contrast_factor + mean. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and in integer or floating point dtype. By default, the layer will output floats. The output value will be clipped to the range [0, 255], the valid range of RGB colors.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomContrast Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomContrastLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly adjusts contrast during training. This layer will randomly adjust the contrast of an image or images by a random factor. Contrast is adjusted independently for each channel of each image during training. For each channel, this layer computes the mean of the image pixels in the channel and then adjusts each component x of each pixel to (x - mean) * contrast_factor + mean. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and in integer or floating point dtype. By default, the layer will output floats. The output value will be clipped to the range [0, 255], the valid range of RGB colors.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomCropLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomCropLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly crops images during training. During training, this layer will randomly choose a location to crop images down to a target size. The layer will crop all the images in the same batch to the same cropping location. At inference time, and during training if an input image is smaller than the target size, the input will be resized and cropped so as to return the largest possible window in the image that matches the target aspect ratio. If you need to apply random cropping at inference time, set training to True when calling the layer. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomCrop Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomCropLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly crops images during training. During training, this layer will randomly choose a location to crop images down to a target size. The layer will crop all the images in the same batch to the same cropping location. At inference time, and during training if an input image is smaller than the target size, the input will be resized and cropped so as to return the largest possible window in the image that matches the target aspect ratio. If you need to apply random cropping at inference time, set training to True when calling the layer. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomCrop</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomEffectsModel -->

    <Class rdf:about="https://w3id.org/aio/RandomEffectsModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A statistical model where the model parameters are random variables.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>REM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Random Effects Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomEffectsModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A statistical model where the model parameters are random variables.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Random_effects_model|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomFlipLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomFlipLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly flips images during training. This layer will flip the images horizontally and or vertically based on the mode attribute. During inference time, the output will be identical to input. Call the layer with training=True to flip the input. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomFlip Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomFlipLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly flips images during training. This layer will flip the images horizontally and or vertically based on the mode attribute. During inference time, the output will be identical to input. Call the layer with training=True to flip the input. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomForest -->

    <Class rdf:about="https://w3id.org/aio/RandomForest">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/EnsembleLearning"/>
        <obo:IAO_0000115>An ensemble learning method for classification, regression, and other tasks that constructs a multitude of decision trees during training.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Random Forest</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomForest"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An ensemble learning method for classification, regression, and other tasks that constructs a multitude of decision trees during training.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Random_forest|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomHeightLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomHeightLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly varies image height during training. This layer adjusts the height of a batch of images by a random factor. The input should be a 3D (unbatched) or 4D (batched) tensor in the &quot;channels_last&quot; image data format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats. By default, this layer is inactive during inference.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomHeight Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomHeightLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly varies image height during training. This layer adjusts the height of a batch of images by a random factor. The input should be a 3D (unbatched) or 4D (batched) tensor in the &quot;channels_last&quot; image data format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats. By default, this layer is inactive during inference.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomHeight</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomRotationLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomRotationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly rotates images during training.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomRotation Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomRotationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly rotates images during training.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomTranslationLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomTranslationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly translates images during training. This layer will apply random translations to each image during training, filling empty space according to fill_mode. aInput pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomTranslation Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomTranslationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly translates images during training. This layer will apply random translations to each image during training, filling empty space according to fill_mode. aInput pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomTranslation</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomWidthLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomWidthLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly varies image width during training. This layer will randomly adjusts the width of a batch of images of a batch of images by a random factor. The input should be a 3D (unbatched) or 4D (batched) tensor in the &quot;channels_last&quot; image data format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats. By default, this layer is inactive during inference.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomWidth Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomWidthLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly varies image width during training. This layer will randomly adjusts the width of a batch of images of a batch of images by a random factor. The input should be a 3D (unbatched) or 4D (batched) tensor in the &quot;channels_last&quot; image data format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats. By default, this layer is inactive during inference.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomWidth</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RandomZoomLayer -->

    <Class rdf:about="https://w3id.org/aio/RandomZoomLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A preprocessing layer which randomly zooms images during training. This layer will randomly zoom in or out on each axis of an image independently, filling empty space according to fill_mode.Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RandomZoom Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RandomZoomLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which randomly zooms images during training. This layer will randomly zoom in or out on each axis of an image independently, filling empty space according to fill_mode.Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RankingBias -->

    <Class rdf:about="https://w3id.org/aio/RankingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AnchoringBias"/>
        <obo:IAO_0000115>The idea that top-ranked results are the most relevant and important, leading to more clicks than other results.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Ranking Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RankingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The idea that top-ranked results are the most relevant and important, leading to more clicks than other results.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RashomonEffectBias -->

    <Class rdf:about="https://w3id.org/aio/RashomonEffectBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Differences in perspective, memory, recall, interpretation, and reporting of the same event by multiple persons or witnesses.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Rashomon Effect</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Rashomon Principle</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Rashomon Effect Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RashomonEffectBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Differences in perspective, memory, recall, interpretation, and reporting of the same event by multiple persons or witnesses.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReLUFunction -->

    <Class rdf:about="https://w3id.org/aio/ReLUFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>The ReLU activation function returns: max(x, 0), the element-wise maximum of 0 and the input tensor.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ReLU</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Rectified Linear Unit</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>ReLU Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReLUFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The ReLU activation function returns: max(x, 0), the element-wise maximum of 0 and the input tensor.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReLULayer -->

    <Class rdf:about="https://w3id.org/aio/ReLULayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <obo:IAO_0000115>Rectified Linear Unit activation function. With default values, it returns element-wise max(x, 0).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ReLU Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReLULayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Rectified Linear Unit activation function. With default values, it returns element-wise max(x, 0).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReasoningLLM -->

    <Class rdf:about="https://w3id.org/aio/ReasoningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A reasoning LLM incorporates explicit reasoning capabilities, leveraging logical rules, axioms, or external knowledge to make deductive inferences during language tasks.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Rational Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Reasoning Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>logical inferences</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>reasoning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Reasoning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReasoningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A reasoning LLM incorporates explicit reasoning capabilities, leveraging logical rules, axioms, or external knowledge to make deductive inferences during language tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.18653/v1/2023.acl-long.347|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RecurrentLayer -->

    <Class rdf:about="https://w3id.org/aio/RecurrentLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer of an RNB, composed of recurrent units and with the number of which is the hidden size of the layer.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Recurrent Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer of an RNB, composed of recurrent units and with the number of which is the hidden size of the layer.</annotatedTarget>
        <oboInOwl:hasDbXref>https://docs.nvidia.com/deepLearning/performance/dl-performance-recurrent/index.html#recurrent-layer</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RecurrentNeuralNetwork -->

    <Class rdf:about="https://w3id.org/aio/RecurrentNeuralNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A recurrent neural network (RNN) has connections forming a directed graph along a temporal sequence, enabling dynamic temporal behavior.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>RN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>RecNN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Recurrent Network</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Memory Cell, Output</rdfs:comment>
        <rdfs:label>Recurrent Neural Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RecurrentNeuralNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A recurrent neural network (RNN) has connections forming a directed graph along a temporal sequence, enabling dynamic temporal behavior.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Recurrent_neural_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RecursiveLLM -->

    <Class rdf:about="https://w3id.org/aio/RecursiveLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A recursive language model uses recursive neural network architectures like TreeLSTMs to learn syntactic composition functions, improving systematic generalization abilities.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Recursive Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Self-Attending Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>iterative refinement</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>self-attention</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Recursive LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RecursiveLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A recursive language model uses recursive neural network architectures like TreeLSTMs to learn syntactic composition functions, improving systematic generalization abilities.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RecursiveLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/RecursiveLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A recursive language model uses recursive neural network architectures like TreeLSTMs to learn syntactic composition functions, improving systematic generalization abilities.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>RLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Compositional generalization</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Recursive Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RecursiveLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A recursive language model uses recursive neural network architectures like TreeLSTMs to learn syntactic composition functions, improving systematic generalization abilities.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.1609/aaai.v33i01.33017450|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RecursiveNeuralNetwork -->

    <Class rdf:about="https://w3id.org/aio/RecursiveNeuralNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A recursive neural network applies the same set of weights recursively over structured input to generate structured or scalar predictions.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>RecuNN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>RvNN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Recursive Neural Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RecursiveNeuralNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A recursive neural network applies the same set of weights recursively over structured input to generate structured or scalar predictions.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Recursive_neural_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RegressionAnalysis -->

    <Class rdf:about="https://w3id.org/aio/RegressionAnalysis">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SupervisedLearning"/>
        <obo:IAO_0000115>A set of statistical processes for estimating the relationships between a dependent variable and one or more independent variables.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Regression analysis</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Regression model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Regression Analysis</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A set of statistical processes for estimating the relationships between a dependent variable and one or more independent variables.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Regression_analysis|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RegularizationLayer -->

    <Class rdf:about="https://w3id.org/aio/RegularizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes. Regularization penalties are applied on a per-layer basis.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Regularization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes. Regularization penalties are applied on a per-layer basis.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/api/layers/regularizers/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReinforcementLearning -->

    <Class rdf:about="https://w3id.org/aio/ReinforcementLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that do not require labeled input/output pairs or explicit correction of sub-optimal actions, focusing instead on balancing exploration and exploitation to optimize performance over time.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Reinforcement Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReinforcementLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that do not require labeled input/output pairs or explicit correction of sub-optimal actions, focusing instead on balancing exploration and exploitation to optimize performance over time.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Reinforcement_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReinforcementLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/ReinforcementLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An RL-LLM is a language model fine-tuned using reinforcement learning, where the model receives rewards for generating text that satisfies certain desired properties or objectives. This can improve the quality, safety, or alignment of generated text.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>RL-Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Reinforcement Learning Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>decision transformers</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>reward modeling</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Reinforcement Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReinforcementLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An RL-LLM is a language model fine-tuned using reinforcement learning, where the model receives rewards for generating text that satisfies certain desired properties or objectives. This can improve the quality, safety, or alignment of generated text.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RepeatVectorLayer -->

    <Class rdf:about="https://w3id.org/aio/RepeatVectorLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Repeats the input n times.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>RepeatVector Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RepeatVectorLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Repeats the input n times.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RepresentationBias -->

    <Class rdf:about="https://w3id.org/aio/RepresentationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias due to non-random sampling of subgroups, making trends non-generalizable to new populations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Representation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RepresentationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias due to non-random sampling of subgroups, making trends non-generalizable to new populations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RepresentationLearning -->

    <Class rdf:about="https://w3id.org/aio/RepresentationLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Discovering representations required for feature detection or classification from raw data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Feature Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Representation Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RepresentationLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Discovering representations required for feature detection or classification from raw data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Feature_learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RescalingLayer -->

    <Class rdf:about="https://w3id.org/aio/RescalingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ImagePreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which rescales input values to a new range.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Rescaling Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RescalingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which rescales input values to a new range.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReshapeLayer -->

    <Class rdf:about="https://w3id.org/aio/ReshapeLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Layer that reshapes inputs into the given shape.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Reshape Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReshapeLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that reshapes inputs into the given shape.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ReshapingLayer -->

    <Class rdf:about="https://w3id.org/aio/ReshapingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Reshape layers are used to change the shape of the input.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Reshape Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Reshaping Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Reshape layers are used to change the shape of the input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/api/layers/reshaping_layers/reshape/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ResidualNeuralNetwork -->

    <Class rdf:about="https://w3id.org/aio/ResidualNeuralNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A residual neural network (ResNet) employs skip connections to bypass certain layers, facilitating the learning of residual functions.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DRN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Deep Residual Network</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>ResNN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>ResNet</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Weight, BN, ReLU, Weight, BN, Addition, ReLU</rdfs:comment>
        <rdfs:label>Residual Neural Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ResidualNeuralNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A residual neural network (ResNet) employs skip connections to bypass certain layers, facilitating the learning of residual functions.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Residual_neural_network|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ResizingLayer -->

    <Class rdf:about="https://w3id.org/aio/ResizingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ImagePreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which resizes images. This layer resizes an image input to a target height and width. The input should be a 4D (batched) or 3D (unbatched) tensor in &quot;channels_last&quot; format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats. This layer can be called on tf.RaggedTensor batches of input images of distinct sizes, and will resize the outputs to dense tensors of uniform size.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Resizing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ResizingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which resizes images. This layer resizes an image input to a target height and width. The input should be a 4D (batched) or 3D (unbatched) tensor in &quot;channels_last&quot; format. Input pixel values can be of any range (e.g. [0., 1.) or [0, 255]) and of interger or floating point dtype. By default, the layer will output floats. This layer can be called on tf.RaggedTensor batches of input images of distinct sizes, and will resize the outputs to dense tensors of uniform size.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Resizing</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RestrictedBoltzmannMachine -->

    <Class rdf:about="https://w3id.org/aio/RestrictedBoltzmannMachine">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BoltzmannMachineNetwork"/>
        <obo:IAO_0000115>A restricted Boltzmann machine (RBM) is a generative stochastic neural network that learns the probability distribution of its input data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>RBM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Backfed Input, Probabilistic Hidden</rdfs:comment>
        <rdfs:label>Restricted Boltzmann Machine</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RestrictedBoltzmannMachine"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A restricted Boltzmann machine (RBM) is a generative stochastic neural network that learns the probability distribution of its input data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Retrieval-AugmentedLLM -->

    <Class rdf:about="https://w3id.org/aio/Retrieval-AugmentedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A retrieval-augmented LLM combines a pre-trained language model with a retrieval system that can access external knowledge sources. This allows the model to condition its generation on relevant retrieved knowledge, improving factual accuracy and knowledge grounding.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Retrieval-Augmented Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>knowledge grounding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>open-book question answering</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Retrieval-Augmented LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Retrieval-AugmentedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A retrieval-augmented LLM combines a pre-trained language model with a retrieval system that can access external knowledge sources. This allows the model to condition its generation on relevant retrieved knowledge, improving factual accuracy and knowledge grounding.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/RidgeRegression -->

    <Class rdf:about="https://w3id.org/aio/RidgeRegression">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A method of estimating the coefficients of multiple regression models in scenarios where the independent variables are highly correlated.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Ridge Regression</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/RidgeRegression"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A method of estimating the coefficients of multiple regression models in scenarios where the independent variables are highly correlated.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Ridge_regression|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SELUFunction -->

    <Class rdf:about="https://w3id.org/aio/SELUFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>The SELU activation function multiplies scale (&gt; 1) with the output of the ELU function to ensure a slope larger than one for positive inputs.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SELU</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Scaled Exponential Linear Unit</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>SELU Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SELUFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The SELU activation function multiplies scale (&gt; 1) with the output of the ELU function to ensure a slope larger than one for positive inputs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/selu</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SelectionAndSamplingBias -->

    <Class rdf:about="https://w3id.org/aio/SelectionAndSamplingBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ComputationalBias"/>
        <obo:IAO_0000115>Bias introduced by non-random selection of individuals, groups, or data, failing to ensure representativeness.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Sampling Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Selection Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Selection Effect</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Selection And Sampling Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias introduced by non-random selection of individuals, groups, or data, failing to ensure representativeness.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SelectiveAdherenceBias -->

    <Class rdf:about="https://w3id.org/aio/SelectiveAdherenceBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>The tendency to selectively adopt algorithmic advice that matches pre-existing beliefs and stereotypes.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Selective Adherence Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SelectiveAdherenceBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The tendency to selectively adopt algorithmic advice that matches pre-existing beliefs and stereotypes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Self-SupervisedLLM -->

    <Class rdf:about="https://w3id.org/aio/Self-SupervisedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A self-supervised LLM learns rich representations by solving pretext tasks that involve predicting parts of the input from other observed parts of the data, without relying on human-annotated labels.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Self-Supervised LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Pretext tasks</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Self-Supervised LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Self-SupervisedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A self-supervised LLM learns rich representations by solving pretext tasks that involve predicting parts of the input from other observed parts of the data, without relying on human-annotated labels.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Self-supervisedLearning -->

    <Class rdf:about="https://w3id.org/aio/Self-supervisedLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Regarded as an intermediate form between supervised and unsupervised learning, self-supervised learning involves predicting parts of the input data from other observed parts without relying on human-annotated labels.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Self-supervised Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Self-supervisedLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Regarded as an intermediate form between supervised and unsupervised learning, self-supervised learning involves predicting parts of the input data from other observed parts without relying on human-annotated labels.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Self-supervised_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Semi-SupervisedLLM -->

    <Class rdf:about="https://w3id.org/aio/Semi-SupervisedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A semi-supervised LLM combines self-supervised pretraining on unlabeled data with supervised fine-tuning on labeled task data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Semi-Supervised Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>self-training</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Semi-Supervised LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Semi-SupervisedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A semi-supervised LLM combines self-supervised pretraining on unlabeled data with supervised fine-tuning on labeled task data.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SeparableConvolution1DLayer -->

    <Class rdf:about="https://w3id.org/aio/SeparableConvolution1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>Depthwise separable 1D convolution. This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If use_bias is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output.a</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SeparableConv1D Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SeparableConvolution1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SeparableConvolution1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Depthwise separable 1D convolution. This layer performs a depthwise convolution that acts separately on channels, followed by a pointwise convolution that mixes channels. If use_bias is True and a bias initializer is provided, it adds a bias vector to the output. It then optionally applies an activation function to produce the final output.a</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SeparableConvolution2DLayer -->

    <Class rdf:about="https://w3id.org/aio/SeparableConvolution2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ConvolutionalLayer"/>
        <obo:IAO_0000115>Depthwise separable 2D convolution. Separable convolutions consist of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes the resulting output channels. The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step. Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SeparableConv2D Layer</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SeparableConvolution2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SeparableConvolution2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Depthwise separable 2D convolution. Separable convolutions consist of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes the resulting output channels. The depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step. Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SigmoidFunction -->

    <Class rdf:about="https://w3id.org/aio/SigmoidFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>Applies the sigmoid activation function sigmoid(x) = 1 / (1 + exp(-x)). For small values (&lt;-5), sigmoid returns a value close to zero, and for large values (&gt;5) the result of the function gets close to 1. Sigmoid is equivalent to a 2-element Softmax, where the second element is assumed to be zero. The sigmoid function always returns a value between 0 and 1.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Sigmoid Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SigmoidFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies the sigmoid activation function sigmoid(x) = 1 / (1 + exp(-x)). For small values (&lt;-5), sigmoid returns a value close to zero, and for large values (&gt;5) the result of the function gets close to 1. Sigmoid is equivalent to a 2-element Softmax, where the second element is assumed to be zero. The sigmoid function always returns a value between 0 and 1.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SimpleRNNCellLayer -->

    <Class rdf:about="https://w3id.org/aio/SimpleRNNCellLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Cell class for SimpleRNN. This class processes one step within the whole time sequence input, whereas tf.keras.layer.SimpleRNN processes the whole sequence.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SimpleRNNCell Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SimpleRNNCellLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Cell class for SimpleRNN. This class processes one step within the whole time sequence input, whereas tf.keras.layer.SimpleRNN processes the whole sequence.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SimpleRNNLayer -->

    <Class rdf:about="https://w3id.org/aio/SimpleRNNLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>Fully-connected RNN where the output is to be fed back to input.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SimpleRNN Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SimpleRNNLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Fully-connected RNN where the output is to be fed back to input.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SocietalBias -->

    <Class rdf:about="https://w3id.org/aio/SocietalBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>Bias characterized by being for or against groups or individuals based on social identities, demographic factors, or immutable physical characteristics, often manifesting as stereotypes.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Social Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Societal Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SocietalBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias characterized by being for or against groups or individuals based on social identities, demographic factors, or immutable physical characteristics, often manifesting as stereotypes.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SoftmaxFunction -->

    <Class rdf:about="https://w3id.org/aio/SoftmaxFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>The elements of the output vector are in range (0, 1) and sum to 1. Each vector is handled independently. The axis argument sets which axis of the input the function is applied along. Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution. The softmax of each vector x is computed as exp(x) / tf.reduce_sum(exp(x)). The input values in are the log-odds of the resulting probability.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Softmax Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SoftmaxFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The elements of the output vector are in range (0, 1) and sum to 1. Each vector is handled independently. The axis argument sets which axis of the input the function is applied along. Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution. The softmax of each vector x is computed as exp(x) / tf.reduce_sum(exp(x)). The input values in are the log-odds of the resulting probability.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SoftmaxLayer -->

    <Class rdf:about="https://w3id.org/aio/SoftmaxLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <obo:IAO_0000115>Softmax activation function.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Softmax Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SoftmaxLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Softmax activation function.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SoftplusFunction -->

    <Class rdf:about="https://w3id.org/aio/SoftplusFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>softplus(x) = log(exp(x) + 1)</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Softplus Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SoftplusFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>softplus(x) = log(exp(x) + 1)</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/softplus</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SoftsignFunction -->

    <Class rdf:about="https://w3id.org/aio/SoftsignFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>softsign(x) = x / (abs(x) + 1)</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Softsign Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SoftsignFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>softsign(x) = x / (abs(x) + 1)</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/softsign</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SparseAutoEncoder -->

    <Class rdf:about="https://w3id.org/aio/SparseAutoEncoder">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AutoEncoderNetwork"/>
        <obo:IAO_0000115>Sparse autoencoders have more hidden units than inputs but constrain only a few hidden units to be active at once, forcing the model to capture unique statistical features of the training data.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SAE</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Sparse AE</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Sparse Autoencoder</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Matched Output-Input</rdfs:comment>
        <rdfs:label>Sparse Auto Encoder</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SparseAutoEncoder"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Sparse autoencoders have more hidden units than inputs but constrain only a few hidden units to be active at once, forcing the model to capture unique statistical features of the training data.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SparseLLM -->

    <Class rdf:about="https://w3id.org/aio/SparseLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A sparse LLM uses techniques like pruning or quantization to reduce the number of non-zero parameters in the model, making it more parameter-efficient and easier to deploy on resource-constrained devices.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Sparse Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>model compression</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>parameter efficiency</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Sparse LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SparseLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A sparse LLM uses techniques like pruning or quantization to reduce the number of non-zero parameters in the model, making it more parameter-efficient and easier to deploy on resource-constrained devices.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SparseLearning -->

    <Class rdf:about="https://w3id.org/aio/SparseLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RepresentationLearning"/>
        <obo:IAO_0000115>Finding sparse representations of input data as a linear combination of basic elements and identifying those elements.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Sparse coding</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Sparse dictionary Learning</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Sparse Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SparseLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Finding sparse representations of input data as a linear combination of basic elements and identifying those elements.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Sparse_dictionary_learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SpatialDropout1DLayer -->

    <Class rdf:about="https://w3id.org/aio/SpatialDropout1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Spatial 1D version of Dropout. This version performs the same function as Dropout, however, it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective Learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SpatialDropout1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SpatialDropout1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Spatial 1D version of Dropout. This version performs the same function as Dropout, however, it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective Learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SpatialDropout2DLayer -->

    <Class rdf:about="https://w3id.org/aio/SpatialDropout2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Spatial 2D version of Dropout. This version performs the same function as Dropout, however, it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective Learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.a</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SpatialDropout2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SpatialDropout2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Spatial 2D version of Dropout. This version performs the same function as Dropout, however, it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective Learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.a</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SpatialDropout3DLayer -->

    <Class rdf:about="https://w3id.org/aio/SpatialDropout3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegularizationLayer"/>
        <obo:IAO_0000115>Spatial 3D version of Dropout. This version performs the same function as Dropout, however, it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective Learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SpatialDropout3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SpatialDropout3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Spatial 3D version of Dropout. This version performs the same function as Dropout, however, it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective Learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/SpatialDropout3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SpatialRegression -->

    <Class rdf:about="https://w3id.org/aio/SpatialRegression">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RegressionAnalysis"/>
        <obo:IAO_0000115>A regression method used to model spatial relationships.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Spatial Regression</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SpatialRegression"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A regression method used to model spatial relationships.</annotatedTarget>
        <oboInOwl:hasDbXref>https://gisgeography.com/spatial-regression-models-arcgis/|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/StackedRNNCellsLayer -->

    <Class rdf:about="https://w3id.org/aio/StackedRNNCellsLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Wrapper allowing a stack of RNN cells to behave as a single cell. Used to implement efficient stacked RNNs.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>StackedRNNCells Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/StackedRNNCellsLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Wrapper allowing a stack of RNN cells to behave as a single cell. Used to implement efficient stacked RNNs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/StackedRNNCells</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/StreetlightEffectBias -->

    <Class rdf:about="https://w3id.org/aio/StreetlightEffectBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Bias where people search only where it is easiest to look.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Streetlight Effect</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Streetlight Effect Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/StreetlightEffectBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias where people search only where it is easiest to look.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/StringLookupLayer -->

    <Class rdf:about="https://w3id.org/aio/StringLookupLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/CategoricalFeaturesPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which maps string features to integer indices.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>StringLookup Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/StringLookupLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which maps string features to integer indices.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SubtractLayer -->

    <Class rdf:about="https://w3id.org/aio/SubtractLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MergingLayer"/>
        <obo:IAO_0000115>Layer that subtracts two inputs. It takes as input a list of tensors of size 2, both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]), also of the same shape.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Subtract Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SubtractLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Layer that subtracts two inputs. It takes as input a list of tensors of size 2, both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]), also of the same shape.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Subtract</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SubwordSegmentation -->

    <Class rdf:about="https://w3id.org/aio/SubwordSegmentation">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DataPreparation"/>
        <obo:IAO_0000115>The process of dividing text into subword units, which are smaller than words but larger than individual characters, to improve the efficiency and effectiveness of natural language processing models by capturing meaningful subunits of words.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Fragmentation</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Part-word Division</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Byte Pair Encoding</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>SentencePiece</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Subword Segmentation</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SubwordSegmentation"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of dividing text into subword units, which are smaller than words but larger than individual characters, to improve the efficiency and effectiveness of natural language processing models by capturing meaningful subunits of words.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SunkCostFallacyBias -->

    <Class rdf:about="https://w3id.org/aio/SunkCostFallacyBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/GroupBias"/>
        <obo:IAO_0000115>The tendency to continue an endeavor due to previously invested resources, despite costs outweighing benefits.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Sunk Cost Fallacy</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Sunk Cost Fallacy Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SunkCostFallacyBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The tendency to continue an endeavor due to previously invested resources, despite costs outweighing benefits.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SupervisedBiclustering -->

    <Class rdf:about="https://w3id.org/aio/SupervisedBiclustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Biclustering"/>
        <obo:IAO_0000115>Methods that simultaneously cluster the rows and columns of a labeled matrix, considering data labels to enhance cluster coherence.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Supervised Block Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Supervised Co-clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Supervised Joint Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Supervised Two-mode Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Supervised Two-way Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Supervised Biclustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SupervisedBiclustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that simultaneously cluster the rows and columns of a labeled matrix, considering data labels to enhance cluster coherence.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Biclustering|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SupervisedClustering -->

    <Class rdf:about="https://w3id.org/aio/SupervisedClustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Clustering"/>
        <obo:IAO_0000115>Methods that group labeled objects such that objects in the same group have similar labels, relative to those in other groups.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Cluster analysis</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Supervised Clustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SupervisedClustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that group labeled objects such that objects in the same group have similar labels, relative to those in other groups.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Cluster_analysis|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SupervisedLearning -->

    <Class rdf:about="https://w3id.org/aio/SupervisedLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that learn a function mapping input to output based on example input-output pairs.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Supervised Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SupervisedLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that learn a function mapping input to output based on example input-output pairs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Supervised_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SupportVectorMachine -->

    <Class rdf:about="https://w3id.org/aio/SupportVectorMachine">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>Support vector machines (SVMs) are supervised learning models for classification and regression analysis, mapping training examples to points in space to maximize the gap between categories.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SVM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>SVN</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Supper Vector Network</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>Support Vector Machine</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SupportVectorMachine"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Support vector machines (SVMs) are supervised learning models for classification and regression analysis, mapping training examples to points in space to maximize the gap between categories.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Support-vector_machine|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SurvivalAnalysis -->

    <Class rdf:about="https://w3id.org/aio/SurvivalAnalysis">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods for analyzing the expected duration of time until one or more events occur, such as death in biological organisms or failure in mechanical systems.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Survival Analysis</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SurvivalAnalysis"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods for analyzing the expected duration of time until one or more events occur, such as death in biological organisms or failure in mechanical systems.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Survival_analysis|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SurvivorshipBias -->

    <Class rdf:about="https://w3id.org/aio/SurvivorshipBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ProcessingBias"/>
        <obo:IAO_0000115>The tendency to focus on items, observations, or people that &quot;survive&quot; a selection process, overlooking those that did not.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Survivorship Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SurvivorshipBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The tendency to focus on items, observations, or people that &quot;survive&quot; a selection process, overlooking those that did not.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SwishFunction -->

    <Class rdf:about="https://w3id.org/aio/SwishFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>x*sigmoid(x). It is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks, it is unbounded above and bounded below.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Swish Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SwishFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>x*sigmoid(x). It is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks, it is unbounded above and bounded below.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/swish</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SymmetricallyConnectedNetwork -->

    <Class rdf:about="https://w3id.org/aio/SymmetricallyConnectedNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>Symmetrically connected networks are a type of recurrent neural network where connections between units are symmetrical, meaning they have equal weights in both directions. This structure allows the network to maintain consistent information flow and equilibrium.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SCN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Symmetrically Connected Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SymmetricallyConnectedNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Symmetrically connected networks are a type of recurrent neural network where connections between units are symmetrical, meaning they have equal weights in both directions. This structure allows the network to maintain consistent information flow and equilibrium.</annotatedTarget>
        <oboInOwl:hasDbXref>https://ieeexplore.ieee.org/document/287176|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SyncBatchNormLayer -->

    <Class rdf:about="https://w3id.org/aio/SyncBatchNormLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/BatchNormalizationLayer"/>
        <obo:IAO_0000115>Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SyncBatchNorm</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>SyncBatchNorm Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SyncBatchNormLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .</annotatedTarget>
        <oboInOwl:hasDbXref>https://pytorch.org/docs/stable/nn.html#normalization-layers</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SystemicBias -->

    <Class rdf:about="https://w3id.org/aio/SystemicBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Bias"/>
        <obo:IAO_0000115>Biases resulting from procedures and practices of particular institutions that operate in ways which result in certain social groups being advantaged or favored and others being disadvantaged or devalued.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Institutional Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Societal Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Systemic Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SystemicBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Biases resulting from procedures and practices of particular institutions that operate in ways which result in certain social groups being advantaged or favored and others being disadvantaged or devalued.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TanhFunction -->

    <Class rdf:about="https://w3id.org/aio/TanhFunction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Function"/>
        <obo:IAO_0000115>Hyperbolic tangent activation function.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>hyperbolic tangent</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/FunctionSubset"/>
        <rdfs:label>Tanh Function</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TanhFunction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Hyperbolic tangent activation function.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TemporalBias -->

    <Class rdf:about="https://w3id.org/aio/TemporalBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias arising from differences in populations and behaviors over time.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Temporal Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TemporalBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising from differences in populations and behaviors over time.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TextPreprocessingLayer -->

    <Class rdf:about="https://w3id.org/aio/TextPreprocessingLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>A layer that performs text data preprocessing operations.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Text Preprocessing Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TextPreprocessingLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A layer that performs text data preprocessing operations.</annotatedTarget>
        <oboInOwl:hasDbXref>https://keras.io/guides/preprocessing_layers/</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TextVectorizationLayer -->

    <Class rdf:about="https://w3id.org/aio/TextVectorizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/TextPreprocessingLayer"/>
        <obo:IAO_0000115>A preprocessing layer which maps text features to integer sequences.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>TextVectorization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TextVectorizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A preprocessing layer which maps text features to integer sequences.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ThresholdedReLULayer -->

    <Class rdf:about="https://w3id.org/aio/ThresholdedReLULayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ActivationLayer"/>
        <obo:IAO_0000115>Thresholded Rectified Linear Unit.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ThresholdedReLU Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ThresholdedReLULayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Thresholded Rectified Linear Unit.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ThresholdedReLU</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TimeDistributedLayer -->

    <Class rdf:about="https://w3id.org/aio/TimeDistributedLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>This wrapper allows to apply a layer to every temporal slice of an input. Every input should be at least 3D, and the dimension of index one of the first input will be considered to be the temporal dimension. Consider a batch of 32 video samples, where each sample is a 128x128 RGB image with channels_last data format, across 10 timesteps. The batch input shape is (32, 10, 128, 128, 3). You can then use TimeDistributed to apply the same Conv2D layer to each of the 10 timesteps, independently:</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>TimeDistributed Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TimeDistributedLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>This wrapper allows to apply a layer to every temporal slice of an input. Every input should be at least 3D, and the dimension of index one of the first input will be considered to be the temporal dimension. Consider a batch of 32 video samples, where each sample is a 128x128 RGB image with channels_last data format, across 10 timesteps. The batch input shape is (32, 10, 128, 128, 3). You can then use TimeDistributed to apply the same Conv2D layer to each of the 10 timesteps, independently:</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TimeSeriesAnalysis -->

    <Class rdf:about="https://w3id.org/aio/TimeSeriesAnalysis">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods for analyzing time series data to extract meaningful statistics and characteristics.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Time Series Analysis</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TimeSeriesAnalysis"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods for analyzing time series data to extract meaningful statistics and characteristics.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Time_series|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TimeSeriesForecasting -->

    <Class rdf:about="https://w3id.org/aio/TimeSeriesForecasting">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that predict future values based on previously observed values.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Time Series Forecasting</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TimeSeriesForecasting"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that predict future values based on previously observed values.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Time_series|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Tokenization -->

    <Class rdf:about="https://w3id.org/aio/Tokenization">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DataPreparation"/>
        <obo:IAO_0000115>The process of converting a sequence of text into smaller, meaningful units called tokens, typically words or subwords, for the purpose of analysis or processing by language models.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Lexical Simplification</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Vocabulary Condensation</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Tokenization</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Vocabulary size reduction</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Tokenization</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Tokenization"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The process of converting a sequence of text into smaller, meaningful units called tokens, typically words or subwords, for the purpose of analysis or processing by language models.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TrainingStrategies -->

    <Class rdf:about="https://w3id.org/aio/TrainingStrategies">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Preprocessing"/>
        <obo:IAO_0000115>The methodologies and approaches used to train machine learning models, including techniques such as supervised learning, unsupervised learning, reinforcement learning, and transfer learning, aimed at optimizing model performance.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Instructional Methods</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Learning Techniques</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Training Strategies</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TrainingStrategies"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The methodologies and approaches used to train machine learning models, including techniques such as supervised learning, unsupervised learning, reinforcement learning, and transfer learning, aimed at optimizing model performance.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TransferLearning -->

    <Class rdf:about="https://w3id.org/aio/TransferLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Methods that reuse or transfer information from previously learned tasks to facilitate the learning of new tasks.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Transfer Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TransferLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that reuse or transfer information from previously learned tasks to facilitate the learning of new tasks.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Transfer_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TransferLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/TransferLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A transfer learning LLM leverages knowledge acquired during training on one task to improve performance on different but related tasks, facilitating more efficient learning and adaptation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Transfer LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>transfer learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Transfer Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TransferLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A transfer learning LLM leverages knowledge acquired during training on one task to improve performance on different but related tasks, facilitating more efficient learning and adaptation.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TransformerLLM -->

    <Class rdf:about="https://w3id.org/aio/TransformerLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/TransformerLanguageModel"/>
        <obo:IAO_0000115>A transformer LLM is a neural network model with large training corpuses and large sets of parameters that uses the transformer architecture based on multi-head attention mechanisms, allowing it to contextualize tokens within a context window for effective language understanding and generation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Transformer Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Transformer LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TransformerLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A transformer LLM is a neural network model with large training corpuses and large sets of parameters that uses the transformer architecture based on multi-head attention mechanisms, allowing it to contextualize tokens within a context window for effective language understanding and generation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TransformerLanguageModel -->

    <Class rdf:about="https://w3id.org/aio/TransformerLanguageModel">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LanguageModel"/>
        <obo:IAO_0000115>A transformer LM is a neural network model that uses the transformer architecture based on multi-head attention mechanisms, allowing it to contextualize tokens within a context window for effective language understanding and generation.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Transformer LM</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Transformer Language Model</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TransformerLanguageModel"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A transformer LM is a neural network model that uses the transformer architecture based on multi-head attention mechanisms, allowing it to contextualize tokens within a context window for effective language understanding and generation.</annotatedTarget>
        <oboInOwl:hasDbXref>https://arxiv.org/abs/1706.03762 | GPT-4o with Seppala et al. 2017|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/TransformerNetwork -->

    <Class rdf:about="https://w3id.org/aio/TransformerNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>A transformer network utilizes attention mechanisms to weigh the significance of each part of the input data, widely used in natural language processing (NLP) and computer vision (CV).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Transformer Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/TransformerNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A transformer network utilizes attention mechanisms to weigh the significance of each part of the input data, widely used in natural language processing (NLP) and computer vision (CV).</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Transformer_(machine_Learning_model)|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UncertaintyBias -->

    <Class rdf:about="https://w3id.org/aio/UncertaintyBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>Bias favoring groups better represented in training data, due to less prediction uncertainty.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Uncertainty Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UncertaintyBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias favoring groups better represented in training data, due to less prediction uncertainty.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UnitNormalizationLayer -->

    <Class rdf:about="https://w3id.org/aio/UnitNormalizationLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/RecurrentLayer"/>
        <obo:IAO_0000115>Unit normalization layer. Normalize a batch of inputs so that each input in the batch has a L2 norm equal to 1 (across the axes specified in axis).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>UnitNormalization Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UnitNormalizationLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Unit normalization layer. Normalize a batch of inputs so that each input in the batch has a L2 norm equal to 1 (across the axes specified in axis).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/UnitNormalization</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UnsupervisedBiclustering -->

    <Class rdf:about="https://w3id.org/aio/UnsupervisedBiclustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Biclustering"/>
        <obo:IAO_0000115>Methods that simultaneously cluster the rows and columns of an unlabeled input matrix to identify submatrices with coherent patterns.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Block Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Co-clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Joint Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Two-mode Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Two-way Clustering</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Unsupervised Biclustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UnsupervisedBiclustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that simultaneously cluster the rows and columns of an unlabeled input matrix to identify submatrices with coherent patterns.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Biclustering|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UnsupervisedClustering -->

    <Class rdf:about="https://w3id.org/aio/UnsupervisedClustering">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Clustering"/>
        <obo:IAO_0000115>Methods that group a set of unlabeled objects such that objects in the same group are more similar to each other than to those in other groups.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Cluster analysis</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Unsupervised Clustering</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UnsupervisedClustering"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Methods that group a set of unlabeled objects such that objects in the same group are more similar to each other than to those in other groups.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Cluster_analysis|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UnsupervisedLLM -->

    <Class rdf:about="https://w3id.org/aio/UnsupervisedLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>An unsupervised LLM is trained solely on unlabeled data using self-supervised objectives like masked language modeling, without any supervised fine-tuning.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Unsupervised Large Language Model</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>self-supervised</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Unsupervised LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UnsupervisedLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>An unsupervised LLM is trained solely on unlabeled data using self-supervised objectives like masked language modeling, without any supervised fine-tuning.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UnsupervisedLearning -->

    <Class rdf:about="https://w3id.org/aio/UnsupervisedLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/MachineLearning"/>
        <obo:IAO_0000115>Algorithms that learn patterns from unlabeled data.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>Unsupervised Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UnsupervisedLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Algorithms that learn patterns from unlabeled data.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Unsupervised_learning|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UnsupervisedPretrainedNetwork -->

    <Class rdf:about="https://w3id.org/aio/UnsupervisedPretrainedNetwork">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Network"/>
        <obo:IAO_0000115>Unsupervised pre-training initializes a discriminative neural net from one trained using an unsupervised criterion, aiding in optimization and overfitting issues.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>UPN</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Unsupervised Pretrained Network</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UnsupervisedPretrainedNetwork"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Unsupervised pre-training initializes a discriminative neural net from one trained using an unsupervised criterion, aiding in optimization and overfitting issues.</annotatedTarget>
        <oboInOwl:hasDbXref>https://metacademy.org/graphs/concepts/unsupervised_pre_training#:~:text=Unsupervised%20pre%2Dtraining%20initializes%20a,optimization%20and%20the%20overfitting%20issues|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UpSampling1DLayer -->

    <Class rdf:about="https://w3id.org/aio/UpSampling1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Upsampling layer for 1D inputs. Repeats each temporal step size times along the time axis.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>UpSampling1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UpSampling1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Upsampling layer for 1D inputs. Repeats each temporal step size times along the time axis.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UpSampling2DLayer -->

    <Class rdf:about="https://w3id.org/aio/UpSampling2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Upsampling layer for 2D inputs. Repeats the rows and columns of the data by size[0] and size[1] respectively.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>UpSampling2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UpSampling2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Upsampling layer for 2D inputs. Repeats the rows and columns of the data by size[0] and size[1] respectively.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UpSampling3DLayer -->

    <Class rdf:about="https://w3id.org/aio/UpSampling3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Upsampling layer for 3D inputs.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>UpSampling3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UpSampling3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Upsampling layer for 3D inputs.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UseAndInterpretationBias -->

    <Class rdf:about="https://w3id.org/aio/UseAndInterpretationBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ComputationalBias"/>
        <obo:IAO_0000115>Bias inappropriately analyzing ambiguous stimuli, scenarios, and events.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Interpretive Bias</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Use And Interpretation Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UseAndInterpretationBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias inappropriately analyzing ambiguous stimuli, scenarios, and events.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/UserInteractionBias -->

    <Class rdf:about="https://w3id.org/aio/UserInteractionBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/IndividualBias"/>
        <obo:IAO_0000115>Bias arising when a user imposes their own biases during interaction with data, output, results, etc.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>User Interaction Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/UserInteractionBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Bias arising when a user imposes their own biases during interaction with data, output, results, etc.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/VariationalAutoEncoder -->

    <Class rdf:about="https://w3id.org/aio/VariationalAutoEncoder">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/AutoEncoderNetwork"/>
        <obo:IAO_0000115>A variational autoencoder (VAE) is a type of artificial neural network used for unsupervised learning. It consists of an encoder, which maps input data to a latent space, and a decoder, which reconstructs the input data from the latent space. Unlike traditional autoencoders, VAEs impose a probabilistic structure on the latent space, enabling them to generate new data samples by sampling from the learned latent distribution. This probabilistic approach allows VAEs to learn smooth and meaningful latent representations, making them useful for tasks such as data generation, anomaly detection, and semi-supervised learning.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>VAE</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Probabilistic Hidden, Matched Output-Input</rdfs:comment>
        <rdfs:label>Variational Auto Encoder</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/VariationalAutoEncoder"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A variational autoencoder (VAE) is a type of artificial neural network used for unsupervised learning. It consists of an encoder, which maps input data to a latent space, and a decoder, which reconstructs the input data from the latent space. Unlike traditional autoencoders, VAEs impose a probabilistic structure on the latent space, enabling them to generate new data samples by sampling from the learned latent distribution. This probabilistic approach allows VAEs to learn smooth and meaningful latent representations, making them useful for tasks such as data generation, anomaly detection, and semi-supervised learning.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/VocabularyReduction -->

    <Class rdf:about="https://w3id.org/aio/VocabularyReduction">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DataPreparation"/>
        <obo:IAO_0000115>The technique of limiting the number of unique tokens in a language model’s vocabulary by merging or eliminating less frequent tokens, thereby optimizing computational efficiency and resource usage.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Lexical Simplification</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>Vocabulary Condensation</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>Tokenization</oboInOwl:hasRelatedSynonym>
        <oboInOwl:hasRelatedSynonym>Vocabulary size reduction</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/PreprocessingSubset"/>
        <rdfs:label>Vocabulary Reduction</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/VocabularyReduction"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>The technique of limiting the number of unique tokens in a language model’s vocabulary by merging or eliminating less frequent tokens, thereby optimizing computational efficiency and resource usage.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/WrapperLayer -->

    <Class rdf:about="https://w3id.org/aio/WrapperLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Layer"/>
        <obo:IAO_0000115>Abstract wrapper base class. Wrappers take another layer and augment it in various ways. Do not use this class as a layer, it is only an abstract base class. Two usable wrappers are the TimeDistributed and Bidirectional wrappers.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>Wrapper Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/WrapperLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Abstract wrapper base class. Wrappers take another layer and augment it in various ways. Do not use this class as a layer, it is only an abstract base class. Two usable wrappers are the TimeDistributed and Bidirectional wrappers.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/Wrapper</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Zero-ShotLearningLLM -->

    <Class rdf:about="https://w3id.org/aio/Zero-ShotLearningLLM">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/LargeLanguageModel"/>
        <obo:IAO_0000115>A zero-shot learning LLM performs tasks or understands concepts it has not explicitly been trained on, demonstrating a high degree of generalization and understanding.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Zero-Shot LLM</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>zero-shot learning</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Zero-Shot Learning LLM</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Zero-ShotLearningLLM"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A zero-shot learning LLM performs tasks or understands concepts it has not explicitly been trained on, demonstrating a high degree of generalization and understanding.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Zero-shotLearning -->

    <Class rdf:about="https://w3id.org/aio/Zero-shotLearning">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DeepNeuralNetwork"/>
        <obo:IAO_0000115>Predicting classes at test time from classes not observed during training.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ZSL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:label>Zero-shot Learning</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Zero-shotLearning"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Predicting classes at test time from classes not observed during training.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Zero-shot_learning|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ZeroPadding1DLayer -->

    <Class rdf:about="https://w3id.org/aio/ZeroPadding1DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Zero-padding layer for 1D input (e.g. temporal sequence).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ZeroPadding1D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ZeroPadding1DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Zero-padding layer for 1D input (e.g. temporal sequence).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding1D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ZeroPadding2DLayer -->

    <Class rdf:about="https://w3id.org/aio/ZeroPadding2DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Zero-padding layer for 2D input (e.g. picture). This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ZeroPadding2D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ZeroPadding2DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Zero-padding layer for 2D input (e.g. picture). This layer can add rows and columns of zeros at the top, bottom, left and right side of an image tensor.</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ZeroPadding3DLayer -->

    <Class rdf:about="https://w3id.org/aio/ZeroPadding3DLayer">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ReshapingLayer"/>
        <obo:IAO_0000115>Zero-padding layer for 3D data (spatial or spatio-temporal).</obo:IAO_0000115>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/LayerSubset"/>
        <rdfs:label>ZeroPadding3D Layer</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ZeroPadding3DLayer"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Zero-padding layer for 3D data (spatial or spatio-temporal).</annotatedTarget>
        <oboInOwl:hasDbXref>https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding3D</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/node2vec-CBOW -->

    <Class rdf:about="https://w3id.org/aio/node2vec-CBOW">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/word2vec-CBOW"/>
        <obo:IAO_0000115>In the continuous bag-of-words architecture, the model predicts the current node from a window of surrounding context nodes, with the order of context nodes not influencing prediction.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>N2V-CBOW</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>CBOW</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>node2vec-CBOW</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/node2vec-CBOW"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>In the continuous bag-of-words architecture, the model predicts the current node from a window of surrounding context nodes, with the order of context nodes not influencing prediction.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Word2vec|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/node2vec-SkipGram -->

    <Class rdf:about="https://w3id.org/aio/node2vec-SkipGram">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/word2vec-SkipGram"/>
        <obo:IAO_0000115>In the continuous skip-gram architecture, the model uses the current node to predict the surrounding window of context nodes, weighing nearby context nodes more heavily than distant ones.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>N2V-SkipGram</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>SkipGram</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>node2vec-SkipGram</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/node2vec-SkipGram"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>In the continuous skip-gram architecture, the model uses the current node to predict the surrounding window of context nodes, weighing nearby context nodes more heavily than distant ones.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Word2vec|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/t-DistributedStochasticNeighborembedding -->

    <Class rdf:about="https://w3id.org/aio/t-DistributedStochasticNeighborembedding">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/DimensionalityReduction"/>
        <obo:IAO_0000115>A statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>t-SNE</oboInOwl:hasExactSynonym>
        <oboInOwl:hasExactSynonym>tSNE</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/MachineLearningSubset"/>
        <rdfs:label>t-Distributed Stochastic Neighbor embedding</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/t-DistributedStochasticNeighborembedding"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A statistical method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding|GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/word2vec-CBOW -->

    <Class rdf:about="https://w3id.org/aio/word2vec-CBOW">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ArtificialNeuralNetwork"/>
        <obo:IAO_0000115>In the continuous bag-of-words (CBOW) architecture, the model predicts the current word from a window of surrounding context words, ignoring the order of context words.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>W2V-CBOW</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>CBOW</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>word2vec-CBOW</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/word2vec-CBOW"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>In the continuous bag-of-words (CBOW) architecture, the model predicts the current word from a window of surrounding context words, ignoring the order of context words.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Word2vec|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/word2vec-SkipGram -->

    <Class rdf:about="https://w3id.org/aio/word2vec-SkipGram">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/ArtificialNeuralNetwork"/>
        <obo:IAO_0000115>In the continuous skip-gram architecture, the model predicts surrounding context words from the current word, giving more weight to nearby context words than distant ones.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>W2V-SkipGram</oboInOwl:hasExactSynonym>
        <oboInOwl:hasRelatedSynonym>SkipGram</oboInOwl:hasRelatedSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/NetworkSubset"/>
        <rdfs:comment>Layers: Input, Hidden, Output</rdfs:comment>
        <rdfs:label>word2vec-SkipGram</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/word2vec-SkipGram"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>In the continuous skip-gram architecture, the model predicts surrounding context words from the current word, giving more weight to nearby context words than distant ones.</annotatedTarget>
        <oboInOwl:hasDbXref>https://en.wikipedia.org/wiki/Word2vec|GPT-4o with Sepalla et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutoregressiveConditionalHeteroskedasticity(ARCH) -->

    <Class rdf:about="https://w3id.org/aio/AutoregressiveConditionalHeteroskedasticity(ARCH)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Autoregressive Conditional Heteroskedasticity (ARCH): A model used for time series data that describes the variance of the current error term as a function of the previous periods&apos; error terms, capturing volatility clustering.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ARCH</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Autoregressive Conditional Heteroskedasticity (ARCH)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutoregressiveConditionalHeteroskedasticity(ARCH)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Autoregressive Conditional Heteroskedasticity (ARCH): A model used for time series data that describes the variance of the current error term as a function of the previous periods&apos; error terms, capturing volatility clustering.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutoregressiveDistributedLag(ARDL) -->

    <Class rdf:about="https://w3id.org/aio/AutoregressiveDistributedLag(ARDL)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Autoregressive Distributed Lag (ARDL): A model used in time series analysis that includes lagged values of both the dependent variable and one or more independent variables, capturing dynamic relationships over time.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ARDL</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Autoregressive Distributed Lag (ARDL)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutoregressiveDistributedLag(ARDL)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Autoregressive Distributed Lag (ARDL): A model used in time series analysis that includes lagged values of both the dependent variable and one or more independent variables, capturing dynamic relationships over time.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutoregressiveIntegratedMovingAverage(ARIMA) -->

    <Class rdf:about="https://w3id.org/aio/AutoregressiveIntegratedMovingAverage(ARIMA)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Autoregressive Integrated Moving Average (ARIMA): A class of statistical models for analyzing and forecasting time series data, which combines autoregression (AR), differencing (I), and moving average (MA) components.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ARIMA</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Autoregressive Integrated Moving Average (ARIMA)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutoregressiveIntegratedMovingAverage(ARIMA)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Autoregressive Integrated Moving Average (ARIMA): A class of statistical models for analyzing and forecasting time series data, which combines autoregression (AR), differencing (I), and moving average (MA) components.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/AutoregressiveMovingAverage(ARMA) -->

    <Class rdf:about="https://w3id.org/aio/AutoregressiveMovingAverage(ARMA)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Autoregressive Moving Average (ARMA): A model that combines autoregressive (AR) and moving average (MA) components to represent time series data, suitable for stationary series without the need for differencing.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ARMA</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Autoregressive Moving Average (ARMA)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/AutoregressiveMovingAverage(ARMA)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Autoregressive Moving Average (ARMA): A model that combines autoregressive (AR) and moving average (MA) components to represent time series data, suitable for stationary series without the need for differencing.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/DynamicConditionalCorrelation(DCC) -->

    <Class rdf:about="https://w3id.org/aio/DynamicConditionalCorrelation(DCC)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Dynamic Conditional Correlation (DCC): A multivariate GARCH model that allows for time-varying correlations between different time series, used in financial econometrics to model and forecast covariances.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>DCC</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Dynamic Conditional Correlation (DCC)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/DynamicConditionalCorrelation(DCC)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Dynamic Conditional Correlation (DCC): A multivariate GARCH model that allows for time-varying correlations between different time series, used in financial econometrics to model and forecast covariances.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ExponentialSmoothingStateSpaceModel(ETS) -->

    <Class rdf:about="https://w3id.org/aio/ExponentialSmoothingStateSpaceModel(ETS)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Exponential Smoothing State Space Model (ETS): A framework for forecasting that combines exponential smoothing with state space modeling, allowing for the inclusion of both trend and seasonal components.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>ETS</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Exponential Smoothing State Space Model (ETS)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ExponentialSmoothingStateSpaceModel(ETS)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Exponential Smoothing State Space Model (ETS): A framework for forecasting that combines exponential smoothing with state space modeling, allowing for the inclusion of both trend and seasonal components.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/GeneralizedAutoregressiveConditionalHeteroskedasticity(GARCH) -->

    <Class rdf:about="https://w3id.org/aio/GeneralizedAutoregressiveConditionalHeteroskedasticity(GARCH)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Generalized Autoregressive Conditional Heteroskedasticity (GARCH): An extension of the ARCH model that incorporates lagged conditional variances, allowing for more flexibility in modeling time-varying volatility.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>GARCH</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Generalized Autoregressive Conditional Heteroskedasticity (GARCH)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/GeneralizedAutoregressiveConditionalHeteroskedasticity(GARCH)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Generalized Autoregressive Conditional Heteroskedasticity (GARCH): An extension of the ARCH model that incorporates lagged conditional variances, allowing for more flexibility in modeling time-varying volatility.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/SeasonalAutoregressiveIntegratedMoving-Average(SARIMA) -->

    <Class rdf:about="https://w3id.org/aio/SeasonalAutoregressiveIntegratedMoving-Average(SARIMA)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Seasonal Autoregressive Integrated Moving-Average (SARIMA): An extension of ARIMA that explicitly supports univariate time series data with a seasonal component, combining seasonal differencing with ARIMA modeling.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>SARIMA</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Seasonal Autoregressive Integrated Moving-Average (SARIMA)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/SeasonalAutoregressiveIntegratedMoving-Average(SARIMA)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Seasonal Autoregressive Integrated Moving-Average (SARIMA): An extension of ARIMA that explicitly supports univariate time series data with a seasonal component, combining seasonal differencing with ARIMA modeling.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/Simpon&apos;sParadoxBias -->

    <Class rdf:about="https://w3id.org/aio/Simpon&apos;sParadoxBias">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/SelectionAndSamplingBias"/>
        <obo:IAO_0000115>A statistical phenomenon where the association between two variables changes when controlling for another variable.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>Simpson&apos;s Paradox</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/BiasSubset"/>
        <rdfs:label>Simpon&apos;s Paradox Bias</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/Simpon&apos;sParadoxBias"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>A statistical phenomenon where the association between two variables changes when controlling for another variable.</annotatedTarget>
        <oboInOwl:hasDbXref>https://doi.org/10.6028/NIST.SP.1270|GTP-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/ThresholdAutoregressive(TAR) -->

    <Class rdf:about="https://w3id.org/aio/ThresholdAutoregressive(TAR)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Threshold Autoregressive (TAR): A model that allows for different autoregressive processes depending on the regime or state of the time series, enabling the capture of nonlinear behaviors.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>TAR</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Threshold Autoregressive (TAR)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/ThresholdAutoregressive(TAR)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Threshold Autoregressive (TAR): A model that allows for different autoregressive processes depending on the regime or state of the time series, enabling the capture of nonlinear behaviors.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
    


    <!-- https://w3id.org/aio/VectorAutoregression(VAR) -->

    <Class rdf:about="https://w3id.org/aio/VectorAutoregression(VAR)">
        <rdfs:subClassOf rdf:resource="https://w3id.org/aio/Model"/>
        <obo:IAO_0000115>Vector Autoregression (VAR): A statistical model used to capture the linear interdependencies among multiple time series, where each variable is modeled as a linear function of its own past values and the past values of all other variables in the system.</obo:IAO_0000115>
        <oboInOwl:hasExactSynonym>VAR</oboInOwl:hasExactSynonym>
        <oboInOwl:inSubset rdf:resource="https://w3id.org/aio/ModelSubset"/>
        <rdfs:label>Vector Autoregression (VAR)</rdfs:label>
    </Class>
    <Axiom>
        <annotatedSource rdf:resource="https://w3id.org/aio/VectorAutoregression(VAR)"/>
        <annotatedProperty rdf:resource="http://purl.obolibrary.org/obo/IAO_0000115"/>
        <annotatedTarget>Vector Autoregression (VAR): A statistical model used to capture the linear interdependencies among multiple time series, where each variable is modeled as a linear function of its own past values and the past values of all other variables in the system.</annotatedTarget>
        <oboInOwl:hasDbXref>GPT-4o with Seppala et al. 2017</oboInOwl:hasDbXref>
    </Axiom>
</rdf:RDF>



<!-- Generated by the OWL API (version 4.5.29) https://github.com/owlcs/owlapi -->

